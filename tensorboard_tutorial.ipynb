{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('.myenv': venv)",
   "metadata": {
    "interpreter": {
     "hash": "5aaa39649e191831d77573cbbc74c7fd91ccc61f4d87a0274bccea618d27b3d8"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as opt\n",
    "torch.set_printoptions(linewidth=120)\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_correct(preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 6, kernel_size = 5)\n",
    "        self.conv2 = nn.Conv2d(in_channels = 6, out_channels = 12, kernel_size =5)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features = 12*4*4, out_features = 120)\n",
    "        self.fc2 = nn.Linear(in_features = 120, out_features = 60)\n",
    "        self.out = nn.Linear(in_features = 60, out_features = 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "            x = F.relu(self.conv1(x))\n",
    "            x = F.max_pool2d(x, kernel_size = 2, stride = 2)\n",
    "            x = F.relu(self.conv2(x))\n",
    "            x = F.max_pool2d(x, kernel_size = 2, stride = 2)\n",
    "            x = torch.flatten(x, start_dim = 1)\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = self.out(x)\n",
    "\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(root = \"./data\", train = True, download = True, transform = transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size = 100, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = SummaryWriter()\n",
    "model = CNN()\n",
    "images, labels = next(iter(train_loader))\n",
    "grid = torchvision.utils.make_grid(images)\n",
    "tb.add_image(\"images\", grid)\n",
    "tb.add_graph(model, images)\n",
    "tb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch: 0 total_correct: 46597 loss: 351.93421091139317\n",
      "epoch: 1 total_correct: 51676 loss: 227.25896137952805\n",
      "epoch: 2 total_correct: 52354 loss: 209.65638510882854\n",
      "epoch: 3 total_correct: 52514 loss: 202.17722918093204\n",
      "epoch: 4 total_correct: 52875 loss: 191.5535284280777\n",
      "epoch: 5 total_correct: 53107 loss: 187.56945431232452\n",
      "epoch: 6 total_correct: 53252 loss: 184.39352037012577\n",
      "epoch: 7 total_correct: 53178 loss: 184.16533616930246\n",
      "epoch: 8 total_correct: 53427 loss: 179.81141930818558\n",
      "epoch: 9 total_correct: 53472 loss: 177.68081154674292\n"
     ]
    }
   ],
   "source": [
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNN().to(device)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size = 100, shuffle = True)\n",
    "optimizer = opt.Adam(model.parameters(), lr = 0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "tb = SummaryWriter()\n",
    "\n",
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        preds = model(images)\n",
    "\n",
    "        loss = criterion(preds, labels)\n",
    "        total_loss += loss.item()\n",
    "        total_correct += get_num_correct(preds, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    tb.add_scalar(\"Loss\", total_loss, epoch)\n",
    "    tb.add_scalar(\"Correct\", total_correct, epoch)\n",
    "    tb.add_scalar(\"Accuracy\", total_correct/len(train_set), epoch)\n",
    "    tb.add_histogram(\"conv1.bias\", model.conv1.bias, epoch)\n",
    "    tb.add_histogram(\"conv1.weight\", model.conv1.weight, epoch)\n",
    "    tb.add_histogram(\"conv2.bias\", model.conv2.bias, epoch)\n",
    "    tb.add_histogram(\"conv2.weight\", model.conv2.weight, epoch)\n",
    "\n",
    "    print(\"epoch:\", epoch, \"total_correct:\", total_correct, \"loss:\", total_loss)\n",
    "\n",
    "    tb.close()"
   ]
  },
  {
   "source": [
    "# Hyperparameter tunig"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.01, 0.001], [32, 64, 128], [True, False]]\n0.01 32 True\n0.01 32 False\n0.01 64 True\n0.01 64 False\n0.01 128 True\n0.01 128 False\n0.001 32 True\n0.001 32 False\n0.001 64 True\n0.001 64 False\n0.001 128 True\n0.001 128 False\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "parameters = dict(lr = [0.01, 0.001], batch_size = [32,64, 128], shuffle = [True, False])\n",
    "\n",
    "param_values = [v for v in parameters.values()]\n",
    "print(param_values)\n",
    "\n",
    "# Get all possible combinations of parameter values\n",
    "for lr, batch_size, shuffle in product(*param_values):\n",
    "    print(lr, batch_size, shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "run id: 1\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 0 total_correct: 48590 loss: 974.33458911255\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 1 total_correct: 51141 loss: 759.3493862450123\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 2 total_correct: 51297 loss: 739.9819678105414\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 3 total_correct: 51698 loss: 717.3941930010915\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 4 total_correct: 51732 loss: 707.9779039155692\n",
      "___________________________________________________________________\n",
      "run id: 2\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 0 total_correct: 47870 loss: 1025.0641575157642\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 1 total_correct: 50789 loss: 789.9204152449965\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 2 total_correct: 50956 loss: 776.318956349045\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 3 total_correct: 51442 loss: 738.742635935545\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 4 total_correct: 51586 loss: 725.7080324925482\n",
      "___________________________________________________________________\n",
      "run id: 3\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 0 total_correct: 47937 loss: 504.9457623064518\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 1 total_correct: 51073 loss: 371.0729867294431\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 2 total_correct: 51621 loss: 349.9682091474533\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 3 total_correct: 52040 loss: 337.53225111216307\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 4 total_correct: 52255 loss: 328.1260338947177\n",
      "___________________________________________________________________\n",
      "run id: 4\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 0 total_correct: 47704 loss: 514.3740431666374\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 1 total_correct: 51520 loss: 364.39191703498363\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 2 total_correct: 52206 loss: 334.1556203365326\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 3 total_correct: 52300 loss: 332.2931754142046\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 4 total_correct: 52497 loss: 320.7773262858391\n",
      "___________________________________________________________________\n",
      "run id: 5\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 0 total_correct: 46839 loss: 270.2284957766533\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 1 total_correct: 51681 loss: 176.32485945522785\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 2 total_correct: 52359 loss: 161.45240651071072\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 3 total_correct: 52725 loss: 152.60310170054436\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 4 total_correct: 52905 loss: 148.7485356926918\n",
      "___________________________________________________________________\n",
      "run id: 6\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 0 total_correct: 46831 loss: 267.95007559657097\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 1 total_correct: 51656 loss: 175.21047995984554\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 2 total_correct: 52360 loss: 160.5693798661232\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 3 total_correct: 52711 loss: 152.9994999319315\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 4 total_correct: 52895 loss: 147.9932795614004\n",
      "___________________________________________________________________\n",
      "run id: 7\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 0 total_correct: 45495 loss: 1217.7256328463554\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 1 total_correct: 50757 loss: 792.6408716514707\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 2 total_correct: 52164 loss: 668.3706766925752\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 3 total_correct: 52729 loss: 611.6403117626905\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 4 total_correct: 53272 loss: 565.3067608904094\n",
      "___________________________________________________________________\n",
      "run id: 8\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 0 total_correct: 45474 loss: 1198.2352788299322\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 1 total_correct: 50729 loss: 793.9773302823305\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 2 total_correct: 51960 loss: 686.0083816163242\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 3 total_correct: 52642 loss: 624.8670631572604\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 4 total_correct: 53195 loss: 581.8701629787683\n",
      "___________________________________________________________________\n",
      "run id: 9\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 0 total_correct: 43413 loss: 686.4858279526234\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 1 total_correct: 49205 loss: 458.0298022478819\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 2 total_correct: 51194 loss: 380.8899181932211\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 3 total_correct: 52200 loss: 340.9012899696827\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 4 total_correct: 52710 loss: 313.53781681507826\n",
      "___________________________________________________________________\n",
      "run id: 10\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 0 total_correct: 43558 loss: 676.6241102218628\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 1 total_correct: 49462 loss: 444.70363725721836\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 2 total_correct: 51218 loss: 377.9814146757126\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 3 total_correct: 52072 loss: 339.82931946218014\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 4 total_correct: 52583 loss: 315.11767034232616\n",
      "___________________________________________________________________\n",
      "run id: 11\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 0 total_correct: 41334 loss: 391.24553510546684\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 1 total_correct: 47944 loss: 250.46260300278664\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 2 total_correct: 49734 loss: 219.2083328962326\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 3 total_correct: 50938 loss: 195.21079508960247\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 4 total_correct: 51575 loss: 179.8085859119892\n",
      "___________________________________________________________________\n",
      "run id: 12\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 0 total_correct: 41168 loss: 392.47411945462227\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 1 total_correct: 47787 loss: 253.25924903154373\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 2 total_correct: 50019 loss: 215.12056905031204\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 3 total_correct: 51212 loss: 192.27060347795486\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 4 total_correct: 51820 loss: 178.15111203491688\n",
      "___________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "for run_id, (lr,batch_size, shuffle) in enumerate(product(*param_values)):\n",
    "    print(\"run id:\", run_id + 1)\n",
    "    model = CNN().to(device)\n",
    "    train_loader = torch.utils.data.DataLoader(train_set,batch_size = batch_size, shuffle = shuffle)\n",
    "    optimizer = opt.Adam(model.parameters(), lr= lr)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    comment = f' batch_size = {batch_size} lr = {lr} shuffle = {shuffle}'\n",
    "    tb = SummaryWriter(comment=comment)\n",
    "    for epoch in range(5):\n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            preds = model(images)\n",
    "\n",
    "            loss = criterion(preds, labels)\n",
    "            total_loss+= loss.item()\n",
    "            total_correct+= get_num_correct(preds, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        tb.add_scalar(\"Loss\", total_loss, epoch)\n",
    "        tb.add_scalar(\"Correct\", total_correct, epoch)\n",
    "        tb.add_scalar(\"Accuracy\", total_correct/ len(train_set), epoch)\n",
    "\n",
    "        print(\"batch_size:\",batch_size, \"lr:\",lr,\"shuffle:\",shuffle)\n",
    "        print(\"epoch:\", epoch, \"total_correct:\", total_correct, \"loss:\",total_loss)\n",
    "    print(\"___________________________________________________________________\")\n",
    "\n",
    "    tb.add_hparams(\n",
    "            {\"lr\": lr, \"bsize\": batch_size, \"shuffle\":shuffle},\n",
    "            {\n",
    "                \"accuracy\": total_correct/ len(train_set),\n",
    "                \"loss\": total_loss,\n",
    "            },\n",
    "        )\n",
    "\n",
    "tb.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}