2021-04-26 16:01:07.952266: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[INFO  16:01:10] Training run_id 0 with learning_rate 0.0001, beta_1 -100,beta_2 0 and freeze False
[INFO  16:01:16] Start experiment with parametrization:
{
    "dataset": {
        "name": "perm_mnist",
        "kwargs": {
            "batch_size": 100,
            "num_tasks": 10
        }
    },
    "cl_method": "generative_replay",
    "criterion": "cross_entropy",
    "beta_1": -100,
    "beta_2": 0,
    "enc_dimensions": [
        784,
        200,
        200,
        10
    ],
    "dec_class_dimensions": [
        10,
        10
    ],
    "dec_rec_dimensions": [
        10,
        200,
        200,
        784
    ],
    "n_bottleneck": 10,
    "epochs": 10,
    "freeze": false,
    "learning_rate": 0.0001,
    "nonlinearity": "relu",
    "mult_mlp": false,
    "n_replay": 1000,
    "optimizer": "adam",
    "replay_weight": 0.999,
    "seed": null,
    "test_samples": 1,
    "vae_batch_size": 128,
    "vae_epochs": 10,
    "vae_lr": 0.005,
    "vae_n_gaussian": 100,
    "vae_n_hidden": 400,
    "model": "vib_model",
    "log_dir": "",
    "task": "perm_mnist_vib"
}
[INFO  16:01:16] Starting training of task 1
[INFO  16:01:32] epoch 0: train_acc: 0.1031 	 test_acc: 0.1233
[INFO  16:01:47] epoch 1: train_acc: 0.1650 	 test_acc: 0.2339
[INFO  16:02:03] epoch 2: train_acc: 0.2682 	 test_acc: 0.3258
[INFO  16:02:19] epoch 3: train_acc: 0.4224 	 test_acc: 0.5187
[INFO  16:02:34] epoch 4: train_acc: 0.5829 	 test_acc: 0.6325
[INFO  16:02:49] epoch 5: train_acc: 0.6427 	 test_acc: 0.6720
[INFO  16:03:04] epoch 6: train_acc: 0.6848 	 test_acc: 0.7128
[INFO  16:03:19] epoch 7: train_acc: 0.7248 	 test_acc: 0.7513
[INFO  16:03:33] epoch 8: train_acc: 0.7555 	 test_acc: 0.7756
[INFO  16:03:48] epoch 9: train_acc: 0.7795 	 test_acc: 0.7970
[INFO  16:03:51] Task accuracies: {
    "task1": 0.7969,
    "task2": 0.0509
}
[INFO  16:03:51] Mean task accuracy: 0.7969
[INFO  16:03:51] Update replay buffer for generative replay.
[INFO  16:03:53] Starting training of task 2
[INFO  16:04:09] epoch 0: train_acc: 0.3327 	 test_acc: 0.6859
[INFO  16:04:24] epoch 1: train_acc: 0.7647 	 test_acc: 0.8219
[INFO  16:04:39] epoch 2: train_acc: 0.8440 	 test_acc: 0.8676
[INFO  16:04:54] epoch 3: train_acc: 0.8791 	 test_acc: 0.8914
[INFO  16:05:09] epoch 4: train_acc: 0.8992 	 test_acc: 0.9071
[INFO  16:05:25] epoch 5: train_acc: 0.9097 	 test_acc: 0.9154
[INFO  16:05:40] epoch 6: train_acc: 0.9181 	 test_acc: 0.9218
[INFO  16:05:55] epoch 7: train_acc: 0.9240 	 test_acc: 0.9271
[INFO  16:06:10] epoch 8: train_acc: 0.9297 	 test_acc: 0.9322
[INFO  16:06:25] epoch 9: train_acc: 0.9337 	 test_acc: 0.9338
[INFO  16:06:28] Task accuracies: {
    "task1": 0.6641,
    "task2": 0.9338
}
[INFO  16:06:28] Mean task accuracy: 0.7989
[INFO  16:06:28] Training run_id 1 with learning_rate 0.0001, beta_1 -100,beta_2 0 and freeze False
[INFO  16:06:28] Start experiment with parametrization:
{
    "dataset": {
        "name": "perm_mnist",
        "kwargs": {
            "batch_size": 100,
            "num_tasks": 10
        }
    },
    "cl_method": "generative_replay",
    "criterion": "cross_entropy",
    "beta_1": -100,
    "beta_2": 0,
    "enc_dimensions": [
        784,
        200,
        200,
        10
    ],
    "dec_class_dimensions": [
        10,
        10
    ],
    "dec_rec_dimensions": [
        10,
        200,
        200,
        784
    ],
    "n_bottleneck": 10,
    "epochs": 10,
    "freeze": false,
    "learning_rate": 0.0001,
    "nonlinearity": "relu",
    "mult_mlp": false,
    "n_replay": 1000,
    "optimizer": "adam",
    "replay_weight": 0.999,
    "seed": null,
    "test_samples": 1,
    "vae_batch_size": 128,
    "vae_epochs": 10,
    "vae_lr": 0.005,
    "vae_n_gaussian": 100,
    "vae_n_hidden": 400,
    "model": "comparison_model",
    "log_dir": "",
    "task": "perm_mnist_vib"
}
[INFO  16:06:28] Starting training of task 1
[INFO  16:06:41] epoch 0: train_acc: 0.6600 	 test_acc: 0.8569
[INFO  16:06:54] epoch 1: train_acc: 0.8762 	 test_acc: 0.8947
[INFO  16:07:07] epoch 2: train_acc: 0.9051 	 test_acc: 0.9132
[INFO  16:07:20] epoch 3: train_acc: 0.9221 	 test_acc: 0.9244
[INFO  16:07:33] epoch 4: train_acc: 0.9334 	 test_acc: 0.9343
[INFO  16:07:46] epoch 5: train_acc: 0.9408 	 test_acc: 0.9431
[INFO  16:07:59] epoch 6: train_acc: 0.9470 	 test_acc: 0.9481
[INFO  16:08:12] epoch 7: train_acc: 0.9523 	 test_acc: 0.9517
[INFO  16:08:25] epoch 8: train_acc: 0.9560 	 test_acc: 0.9554
[INFO  16:08:37] epoch 9: train_acc: 0.9591 	 test_acc: 0.9589
[INFO  16:10:45] Task accuracies: {
    "task1": 0.959,
    "task2": 0.1032
}
[INFO  16:10:45] Mean task accuracy: 0.9590
[INFO  16:10:45] Update replay buffer for generative replay.
[INFO  16:10:47] Starting training of task 2
[INFO  16:11:01] epoch 0: train_acc: 0.5998 	 test_acc: 0.7723
[INFO  16:11:15] epoch 1: train_acc: 0.7948 	 test_acc: 0.8290
[INFO  16:11:29] epoch 2: train_acc: 0.8322 	 test_acc: 0.8548
[INFO  16:11:42] epoch 3: train_acc: 0.8537 	 test_acc: 0.8720
[INFO  16:11:56] epoch 4: train_acc: 0.8685 	 test_acc: 0.8832
[INFO  16:12:10] epoch 5: train_acc: 0.8801 	 test_acc: 0.8921
[INFO  16:12:24] epoch 6: train_acc: 0.8895 	 test_acc: 0.8988
[INFO  16:12:38] epoch 7: train_acc: 0.8986 	 test_acc: 0.9054
[INFO  16:12:52] epoch 8: train_acc: 0.9063 	 test_acc: 0.9111
[INFO  16:13:06] epoch 9: train_acc: 0.9129 	 test_acc: 0.9172
[INFO  16:13:09] Task accuracies: {
    "task1": 0.9588,
    "task2": 0.9171
}
[INFO  16:13:09] Mean task accuracy: 0.9380
[INFO  16:13:09] Training run_id 2 with learning_rate 0.0001, beta_1 -100,beta_2 0 and freeze False
[INFO  16:13:09] Start experiment with parametrization:
{
    "dataset": {
        "name": "perm_mnist",
        "kwargs": {
            "batch_size": 100,
            "num_tasks": 10
        }
    },
    "cl_method": "generative_replay",
    "criterion": "cross_entropy",
    "beta_1": -100,
    "beta_2": 0,
    "enc_dimensions": [
        784,
        200,
        200,
        100
    ],
    "dec_class_dimensions": [
        100,
        10
    ],
    "dec_rec_dimensions": [
        100,
        200,
        200,
        784
    ],
    "n_bottleneck": 100,
    "epochs": 10,
    "freeze": false,
    "learning_rate": 0.0001,
    "nonlinearity": "relu",
    "mult_mlp": false,
    "n_replay": 1000,
    "optimizer": "adam",
    "replay_weight": 0.999,
    "seed": null,
    "test_samples": 1,
    "vae_batch_size": 128,
    "vae_epochs": 10,
    "vae_lr": 0.005,
    "vae_n_gaussian": 100,
    "vae_n_hidden": 400,
    "model": "vib_model",
    "log_dir": "",
    "task": "perm_mnist_vib"
}
[INFO  16:13:09] Starting training of task 1
[INFO  16:13:22] epoch 0: train_acc: 0.1381 	 test_acc: 0.2346
[INFO  16:13:36] epoch 1: train_acc: 0.3961 	 test_acc: 0.5828
[INFO  16:13:49] epoch 2: train_acc: 0.6895 	 test_acc: 0.7447
[INFO  16:14:02] epoch 3: train_acc: 0.7658 	 test_acc: 0.7944
[INFO  16:14:16] epoch 4: train_acc: 0.8026 	 test_acc: 0.8245
[INFO  16:14:29] epoch 5: train_acc: 0.8306 	 test_acc: 0.8478
[INFO  16:14:43] epoch 6: train_acc: 0.8513 	 test_acc: 0.8593
[INFO  16:14:56] epoch 7: train_acc: 0.8613 	 test_acc: 0.8677
[INFO  16:15:10] epoch 8: train_acc: 0.8674 	 test_acc: 0.8725
[INFO  16:15:23] epoch 9: train_acc: 0.8716 	 test_acc: 0.8779
[INFO  16:15:26] Task accuracies: {
    "task1": 0.8779,
    "task2": 0.117
}
[INFO  16:15:26] Mean task accuracy: 0.8779
[INFO  16:15:26] Update replay buffer for generative replay.
[INFO  16:15:28] Starting training of task 2
[INFO  16:15:42] epoch 0: train_acc: 0.3393 	 test_acc: 0.6343
[INFO  16:15:56] epoch 1: train_acc: 0.7750 	 test_acc: 0.8476
[INFO  16:16:10] epoch 2: train_acc: 0.8588 	 test_acc: 0.8754
[INFO  16:16:24] epoch 3: train_acc: 0.8845 	 test_acc: 0.8966
[INFO  16:16:38] epoch 4: train_acc: 0.9019 	 test_acc: 0.9078
[INFO  16:16:52] epoch 5: train_acc: 0.9125 	 test_acc: 0.9173
[INFO  16:17:06] epoch 6: train_acc: 0.9209 	 test_acc: 0.9236
[INFO  16:17:20] epoch 7: train_acc: 0.9273 	 test_acc: 0.9282
[INFO  16:17:34] epoch 8: train_acc: 0.9312 	 test_acc: 0.9310
[INFO  16:17:48] epoch 9: train_acc: 0.9353 	 test_acc: 0.9354
[INFO  16:17:51] Task accuracies: {
    "task1": 0.5214,
    "task2": 0.9351
}
[INFO  16:17:51] Mean task accuracy: 0.7283
[INFO  16:17:51] Training run_id 3 with learning_rate 0.0001, beta_1 -100,beta_2 0 and freeze False
[INFO  16:17:52] Start experiment with parametrization:
{
    "dataset": {
        "name": "perm_mnist",
        "kwargs": {
            "batch_size": 100,
            "num_tasks": 10
        }
    },
    "cl_method": "generative_replay",
    "criterion": "cross_entropy",
    "beta_1": -100,
    "beta_2": 0,
    "enc_dimensions": [
        784,
        200,
        200,
        100
    ],
    "dec_class_dimensions": [
        100,
        10
    ],
    "dec_rec_dimensions": [
        100,
        200,
        200,
        784
    ],
    "n_bottleneck": 100,
    "epochs": 10,
    "freeze": false,
    "learning_rate": 0.0001,
    "nonlinearity": "relu",
    "mult_mlp": false,
    "n_replay": 1000,
    "optimizer": "adam",
    "replay_weight": 0.999,
    "seed": null,
    "test_samples": 1,
    "vae_batch_size": 128,
    "vae_epochs": 10,
    "vae_lr": 0.005,
    "vae_n_gaussian": 100,
    "vae_n_hidden": 400,
    "model": "comparison_model",
    "log_dir": "",
    "task": "perm_mnist_vib"
}
[INFO  16:17:52] Starting training of task 1
[INFO  16:18:04] epoch 0: train_acc: 0.7196 	 test_acc: 0.8977
[INFO  16:18:16] epoch 1: train_acc: 0.9071 	 test_acc: 0.9195
[INFO  16:18:28] epoch 2: train_acc: 0.9239 	 test_acc: 0.9312
[INFO  16:18:40] epoch 3: train_acc: 0.9347 	 test_acc: 0.9397
[INFO  16:18:52] epoch 4: train_acc: 0.9444 	 test_acc: 0.9444
[INFO  16:19:05] epoch 5: train_acc: 0.9509 	 test_acc: 0.9495
[INFO  16:19:17] epoch 6: train_acc: 0.9560 	 test_acc: 0.9556
[INFO  16:19:29] epoch 7: train_acc: 0.9606 	 test_acc: 0.9583
[INFO  16:19:41] epoch 8: train_acc: 0.9640 	 test_acc: 0.9618
[INFO  16:19:53] epoch 9: train_acc: 0.9672 	 test_acc: 0.9636
[INFO  16:22:02] Task accuracies: {
    "task1": 0.9631,
    "task2": 0.1167
}
[INFO  16:22:02] Mean task accuracy: 0.9631
[INFO  16:22:02] Update replay buffer for generative replay.
[INFO  16:22:04] Starting training of task 2
[INFO  16:22:18] epoch 0: train_acc: 0.6483 	 test_acc: 0.8094
[INFO  16:22:32] epoch 1: train_acc: 0.8272 	 test_acc: 0.8549
[INFO  16:22:46] epoch 2: train_acc: 0.8593 	 test_acc: 0.8770
[INFO  16:23:00] epoch 3: train_acc: 0.8775 	 test_acc: 0.8901
[INFO  16:23:15] epoch 4: train_acc: 0.8890 	 test_acc: 0.9012
[INFO  16:23:29] epoch 5: train_acc: 0.8989 	 test_acc: 0.9078
[INFO  16:23:44] epoch 6: train_acc: 0.9065 	 test_acc: 0.9161
[INFO  16:23:59] epoch 7: train_acc: 0.9130 	 test_acc: 0.9200
[INFO  16:24:14] epoch 8: train_acc: 0.9192 	 test_acc: 0.9255
[INFO  16:24:29] epoch 9: train_acc: 0.9249 	 test_acc: 0.9300
[INFO  16:24:32] Task accuracies: {
    "task1": 0.9632,
    "task2": 0.9303
}
[INFO  16:24:32] Mean task accuracy: 0.9467
[INFO  16:24:32] Training run_id 4 with learning_rate 0.0001, beta_1 -100,beta_2 0 and freeze False
[INFO  16:24:32] Start experiment with parametrization:
{
    "dataset": {
        "name": "perm_mnist",
        "kwargs": {
            "batch_size": 100,
            "num_tasks": 10
        }
    },
    "cl_method": "generative_replay",
    "criterion": "cross_entropy",
    "beta_1": -100,
    "beta_2": 0,
    "enc_dimensions": [
        784,
        200,
        200,
        1000
    ],
    "dec_class_dimensions": [
        1000,
        10
    ],
    "dec_rec_dimensions": [
        1000,
        200,
        200,
        784
    ],
    "n_bottleneck": 1000,
    "epochs": 10,
    "freeze": false,
    "learning_rate": 0.0001,
    "nonlinearity": "relu",
    "mult_mlp": false,
    "n_replay": 1000,
    "optimizer": "adam",
    "replay_weight": 0.999,
    "seed": null,
    "test_samples": 1,
    "vae_batch_size": 128,
    "vae_epochs": 10,
    "vae_lr": 0.005,
    "vae_n_gaussian": 100,
    "vae_n_hidden": 400,
    "model": "vib_model",
    "log_dir": "",
    "task": "perm_mnist_vib"
}
[INFO  16:24:32] Starting training of task 1
[INFO  16:24:47] epoch 0: train_acc: 0.2210 	 test_acc: 0.4775
[INFO  16:25:01] epoch 1: train_acc: 0.6821 	 test_acc: 0.7620
[INFO  16:25:16] epoch 2: train_acc: 0.7953 	 test_acc: 0.8280
[INFO  16:25:30] epoch 3: train_acc: 0.8436 	 test_acc: 0.8647
[INFO  16:25:45] epoch 4: train_acc: 0.8688 	 test_acc: 0.8805
[INFO  16:25:59] epoch 5: train_acc: 0.8773 	 test_acc: 0.8852
[INFO  16:26:13] epoch 6: train_acc: 0.8827 	 test_acc: 0.8909
[INFO  16:26:28] epoch 7: train_acc: 0.8870 	 test_acc: 0.8977
[INFO  16:26:42] epoch 8: train_acc: 0.8903 	 test_acc: 0.8988
[INFO  16:26:57] epoch 9: train_acc: 0.8938 	 test_acc: 0.9001
[INFO  16:27:00] Task accuracies: {
    "task1": 0.8997,
    "task2": 0.0938
}
[INFO  16:27:00] Mean task accuracy: 0.8997
[INFO  16:27:00] Update replay buffer for generative replay.
[INFO  16:27:02] Starting training of task 2
[INFO  16:27:17] epoch 0: train_acc: 0.4806 	 test_acc: 0.8360
[INFO  16:27:32] epoch 1: train_acc: 0.8703 	 test_acc: 0.8956
[INFO  16:27:48] epoch 2: train_acc: 0.9040 	 test_acc: 0.9145
[INFO  16:28:03] epoch 3: train_acc: 0.9210 	 test_acc: 0.9270
[INFO  16:28:18] epoch 4: train_acc: 0.9328 	 test_acc: 0.9369
[INFO  16:28:33] epoch 5: train_acc: 0.9401 	 test_acc: 0.9427
[INFO  16:28:49] epoch 6: train_acc: 0.9456 	 test_acc: 0.9483
[INFO  16:29:04] epoch 7: train_acc: 0.9502 	 test_acc: 0.9488
[INFO  16:29:19] epoch 8: train_acc: 0.9540 	 test_acc: 0.9520
[INFO  16:29:34] epoch 9: train_acc: 0.9568 	 test_acc: 0.9530
[INFO  16:29:37] Task accuracies: {
    "task1": 0.3867,
    "task2": 0.953
}
[INFO  16:29:37] Mean task accuracy: 0.6698
[INFO  16:29:37] Training run_id 5 with learning_rate 0.0001, beta_1 -100,beta_2 0 and freeze False
[INFO  16:29:38] Start experiment with parametrization:
{
    "dataset": {
        "name": "perm_mnist",
        "kwargs": {
            "batch_size": 100,
            "num_tasks": 10
        }
    },
    "cl_method": "generative_replay",
    "criterion": "cross_entropy",
    "beta_1": -100,
    "beta_2": 0,
    "enc_dimensions": [
        784,
        200,
        200,
        1000
    ],
    "dec_class_dimensions": [
        1000,
        10
    ],
    "dec_rec_dimensions": [
        1000,
        200,
        200,
        784
    ],
    "n_bottleneck": 1000,
    "epochs": 10,
    "freeze": false,
    "learning_rate": 0.0001,
    "nonlinearity": "relu",
    "mult_mlp": false,
    "n_replay": 1000,
    "optimizer": "adam",
    "replay_weight": 0.999,
    "seed": null,
    "test_samples": 1,
    "vae_batch_size": 128,
    "vae_epochs": 10,
    "vae_lr": 0.005,
    "vae_n_gaussian": 100,
    "vae_n_hidden": 400,
    "model": "comparison_model",
    "log_dir": "",
    "task": "perm_mnist_vib"
}
[INFO  16:29:38] Starting training of task 1
[INFO  16:29:51] epoch 0: train_acc: 0.7607 	 test_acc: 0.9034
[INFO  16:30:04] epoch 1: train_acc: 0.9126 	 test_acc: 0.9239
[INFO  16:30:17] epoch 2: train_acc: 0.9300 	 test_acc: 0.9352
[INFO  16:30:30] epoch 3: train_acc: 0.9419 	 test_acc: 0.9479
[INFO  16:30:43] epoch 4: train_acc: 0.9507 	 test_acc: 0.9541
[INFO  16:30:56] epoch 5: train_acc: 0.9580 	 test_acc: 0.9552
[INFO  16:31:09] epoch 6: train_acc: 0.9637 	 test_acc: 0.9617
[INFO  16:31:22] epoch 7: train_acc: 0.9686 	 test_acc: 0.9668
[INFO  16:31:35] epoch 8: train_acc: 0.9722 	 test_acc: 0.9680
[INFO  16:31:48] epoch 9: train_acc: 0.9751 	 test_acc: 0.9677
[INFO  16:34:07] Task accuracies: {
    "task1": 0.9671,
    "task2": 0.0816
}
[INFO  16:34:07] Mean task accuracy: 0.9671
[INFO  16:34:07] Update replay buffer for generative replay.
[INFO  16:34:09] Starting training of task 2
[INFO  16:34:25] epoch 0: train_acc: 0.6542 	 test_acc: 0.8051
[INFO  16:34:41] epoch 1: train_acc: 0.8302 	 test_acc: 0.8541
[INFO  16:34:57] epoch 2: train_acc: 0.8639 	 test_acc: 0.8771
[INFO  16:35:13] epoch 3: train_acc: 0.8827 	 test_acc: 0.8910
[INFO  16:35:29] epoch 4: train_acc: 0.8963 	 test_acc: 0.9016
[INFO  16:35:45] epoch 5: train_acc: 0.9064 	 test_acc: 0.9088
[INFO  16:36:01] epoch 6: train_acc: 0.9144 	 test_acc: 0.9165
[INFO  16:36:17] epoch 7: train_acc: 0.9208 	 test_acc: 0.9215
[INFO  16:36:33] epoch 8: train_acc: 0.9272 	 test_acc: 0.9259
[INFO  16:36:49] epoch 9: train_acc: 0.9309 	 test_acc: 0.9305
[INFO  16:36:52] Task accuracies: {
    "task1": 0.9643,
    "task2": 0.9291
}
[INFO  16:36:52] Mean task accuracy: 0.9467
[INFO  16:36:52] Training run_id 6 with learning_rate 0.0001, beta_1 -100,beta_2 0.01 and freeze False
[INFO  16:36:52] Start experiment with parametrization:
{
    "dataset": {
        "name": "perm_mnist",
        "kwargs": {
            "batch_size": 100,
            "num_tasks": 10
        }
    },
    "cl_method": "generative_replay",
    "criterion": "cross_entropy",
    "beta_1": -100,
    "beta_2": 0.01,
    "enc_dimensions": [
        784,
        200,
        200,
        10
    ],
    "dec_class_dimensions": [
        10,
        10
    ],
    "dec_rec_dimensions": [
        10,
        200,
        200,
        784
    ],
    "n_bottleneck": 10,
    "epochs": 10,
    "freeze": false,
    "learning_rate": 0.0001,
    "nonlinearity": "relu",
    "mult_mlp": false,
    "n_replay": 1000,
    "optimizer": "adam",
    "replay_weight": 0.999,
    "seed": null,
    "test_samples": 1,
    "vae_batch_size": 128,
    "vae_epochs": 10,
    "vae_lr": 0.005,
    "vae_n_gaussian": 100,
    "vae_n_hidden": 400,
    "model": "vib_model",
    "log_dir": "",
    "task": "perm_mnist_vib"
}
[INFO  16:36:52] Starting training of task 1
[INFO  16:37:08] epoch 0: train_acc: 0.1154 	 test_acc: 0.1414
[INFO  16:37:23] epoch 1: train_acc: 0.1984 	 test_acc: 0.2976
[INFO  16:37:38] epoch 2: train_acc: 0.3859 	 test_acc: 0.4588
[INFO  16:37:53] epoch 3: train_acc: 0.5240 	 test_acc: 0.5877
[INFO  16:38:09] epoch 4: train_acc: 0.6310 	 test_acc: 0.6568
[INFO  16:38:25] epoch 5: train_acc: 0.6721 	 test_acc: 0.6912
[INFO  16:38:40] epoch 6: train_acc: 0.7083 	 test_acc: 0.7318
[INFO  16:38:56] epoch 7: train_acc: 0.7465 	 test_acc: 0.7663
[INFO  16:39:11] epoch 8: train_acc: 0.7745 	 test_acc: 0.7912
[INFO  16:39:26] epoch 9: train_acc: 0.7958 	 test_acc: 0.8097
[INFO  16:39:29] Task accuracies: {
    "task1": 0.8098,
    "task2": 0.1092
}
[INFO  16:39:29] Mean task accuracy: 0.8098
[INFO  16:39:29] Update replay buffer for generative replay.
[INFO  16:39:31] Starting training of task 2
[INFO  16:39:47] epoch 0: train_acc: 0.2591 	 test_acc: 0.5150
[INFO  16:40:02] epoch 1: train_acc: 0.6594 	 test_acc: 0.7248
[INFO  16:40:18] epoch 2: train_acc: 0.7481 	 test_acc: 0.7743
[INFO  16:40:33] epoch 3: train_acc: 0.7870 	 test_acc: 0.7989
[INFO  16:40:49] epoch 4: train_acc: 0.8066 	 test_acc: 0.8127
[INFO  16:41:04] epoch 5: train_acc: 0.8161 	 test_acc: 0.8151
[INFO  16:41:19] epoch 6: train_acc: 0.8212 	 test_acc: 0.8201
[INFO  16:41:35] epoch 7: train_acc: 0.8252 	 test_acc: 0.8218
[INFO  16:41:50] epoch 8: train_acc: 0.8301 	 test_acc: 0.8310
[INFO  16:42:06] epoch 9: train_acc: 0.8358 	 test_acc: 0.8356
[INFO  16:42:09] Task accuracies: {
    "task1": 0.5152,
    "task2": 0.8348
}
[INFO  16:42:09] Mean task accuracy: 0.6750
[INFO  16:42:09] Training run_id 7 with learning_rate 0.0001, beta_1 -100,beta_2 0.01 and freeze False
[INFO  16:42:09] Start experiment with parametrization:
{
    "dataset": {
        "name": "perm_mnist",
        "kwargs": {
            "batch_size": 100,
            "num_tasks": 10
        }
    },
    "cl_method": "generative_replay",
    "criterion": "cross_entropy",
    "beta_1": -100,
    "beta_2": 0.01,
    "enc_dimensions": [
        784,
        200,
        200,
        10
    ],
    "dec_class_dimensions": [
        10,
        10
    ],
    "dec_rec_dimensions": [
        10,
        200,
        200,
        784
    ],
    "n_bottleneck": 10,
    "epochs": 10,
    "freeze": false,
    "learning_rate": 0.0001,
    "nonlinearity": "relu",
    "mult_mlp": false,
    "n_replay": 1000,
    "optimizer": "adam",
    "replay_weight": 0.999,
    "seed": null,
    "test_samples": 1,
    "vae_batch_size": 128,
    "vae_epochs": 10,
    "vae_lr": 0.005,
    "vae_n_gaussian": 100,
    "vae_n_hidden": 400,
    "model": "comparison_model",
    "log_dir": "",
    "task": "perm_mnist_vib"
}
[INFO  16:42:09] Starting training of task 1
[INFO  16:42:23] epoch 0: train_acc: 0.5918 	 test_acc: 0.8205
[INFO  16:42:36] epoch 1: train_acc: 0.8634 	 test_acc: 0.9039
[INFO  16:42:50] epoch 2: train_acc: 0.9099 	 test_acc: 0.9251
[INFO  16:43:04] epoch 3: train_acc: 0.9278 	 test_acc: 0.9387
[INFO  16:43:18] epoch 4: train_acc: 0.9401 	 test_acc: 0.9439
[INFO  16:43:32] epoch 5: train_acc: 0.9496 	 test_acc: 0.9496
[INFO  16:43:45] epoch 6: train_acc: 0.9552 	 test_acc: 0.9545
[INFO  16:43:59] epoch 7: train_acc: 0.9600 	 test_acc: 0.9628
[INFO  16:44:13] epoch 8: train_acc: 0.9650 	 test_acc: 0.9629
[INFO  16:44:27] epoch 9: train_acc: 0.9680 	 test_acc: 0.9644
[INFO  16:46:51] Task accuracies: {
    "task1": 0.9644,
    "task2": 0.1091
}
[INFO  16:46:51] Mean task accuracy: 0.9644
[INFO  16:46:51] Update replay buffer for generative replay.
[INFO  16:46:53] Starting training of task 2
[INFO  16:47:09] epoch 0: train_acc: 0.6185 	 test_acc: 0.8017
[INFO  16:47:25] epoch 1: train_acc: 0.8246 	 test_acc: 0.8538
[INFO  16:47:40] epoch 2: train_acc: 0.8605 	 test_acc: 0.8792
[INFO  16:47:55] epoch 3: train_acc: 0.8802 	 test_acc: 0.8916
[INFO  16:48:10] epoch 4: train_acc: 0.8926 	 test_acc: 0.9013
[INFO  16:48:25] epoch 5: train_acc: 0.9024 	 test_acc: 0.9084
[INFO  16:48:40] epoch 6: train_acc: 0.9090 	 test_acc: 0.9093
[INFO  16:48:55] epoch 7: train_acc: 0.9152 	 test_acc: 0.9188
[INFO  16:49:10] epoch 8: train_acc: 0.9193 	 test_acc: 0.9234
[INFO  16:49:25] epoch 9: train_acc: 0.9244 	 test_acc: 0.9243
[INFO  16:49:28] Task accuracies: {
    "task1": 0.954,
    "task2": 0.9217
}
[INFO  16:49:28] Mean task accuracy: 0.9378
[INFO  16:49:28] Training run_id 8 with learning_rate 0.0001, beta_1 -100,beta_2 0.01 and freeze False
[INFO  16:49:28] Start experiment with parametrization:
{
    "dataset": {
        "name": "perm_mnist",
        "kwargs": {
            "batch_size": 100,
            "num_tasks": 10
        }
    },
    "cl_method": "generative_replay",
    "criterion": "cross_entropy",
    "beta_1": -100,
    "beta_2": 0.01,
    "enc_dimensions": [
        784,
        200,
        200,
        100
    ],
    "dec_class_dimensions": [
        100,
        10
    ],
    "dec_rec_dimensions": [
        100,
        200,
        200,
        784
    ],
    "n_bottleneck": 100,
    "epochs": 10,
    "freeze": false,
    "learning_rate": 0.0001,
    "nonlinearity": "relu",
    "mult_mlp": false,
    "n_replay": 1000,
    "optimizer": "adam",
    "replay_weight": 0.999,
    "seed": null,
    "test_samples": 1,
    "vae_batch_size": 128,
    "vae_epochs": 10,
    "vae_lr": 0.005,
    "vae_n_gaussian": 100,
    "vae_n_hidden": 400,
    "model": "vib_model",
    "log_dir": "",
    "task": "perm_mnist_vib"
}
[INFO  16:49:28] Starting training of task 1
[INFO  16:49:42] epoch 0: train_acc: 0.1401 	 test_acc: 0.2463
[INFO  16:49:57] epoch 1: train_acc: 0.3789 	 test_acc: 0.5630
[INFO  16:50:11] epoch 2: train_acc: 0.6818 	 test_acc: 0.7496
[INFO  16:50:26] epoch 3: train_acc: 0.7574 	 test_acc: 0.7788
[INFO  16:50:40] epoch 4: train_acc: 0.7870 	 test_acc: 0.8107
[INFO  16:50:55] epoch 5: train_acc: 0.8141 	 test_acc: 0.8301
[INFO  16:51:09] epoch 6: train_acc: 0.8333 	 test_acc: 0.8498
[INFO  16:51:23] epoch 7: train_acc: 0.8529 	 test_acc: 0.8693
[INFO  16:51:38] epoch 8: train_acc: 0.8646 	 test_acc: 0.8762
[INFO  16:51:52] epoch 9: train_acc: 0.8705 	 test_acc: 0.8824
[INFO  16:51:55] Task accuracies: {
    "task1": 0.8823,
    "task2": 0.115
}
[INFO  16:51:55] Mean task accuracy: 0.8823
[INFO  16:51:55] Update replay buffer for generative replay.
[INFO  16:51:58] Starting training of task 2
[INFO  16:52:13] epoch 0: train_acc: 0.2122 	 test_acc: 0.3844
[INFO  16:52:27] epoch 1: train_acc: 0.5951 	 test_acc: 0.7483
[INFO  16:52:42] epoch 2: train_acc: 0.7769 	 test_acc: 0.7941
[INFO  16:52:57] epoch 3: train_acc: 0.8059 	 test_acc: 0.8170
[INFO  16:53:12] epoch 4: train_acc: 0.8178 	 test_acc: 0.8268
[INFO  16:53:26] epoch 5: train_acc: 0.8261 	 test_acc: 0.8312
[INFO  16:53:41] epoch 6: train_acc: 0.8354 	 test_acc: 0.8414
[INFO  16:53:57] epoch 7: train_acc: 0.8438 	 test_acc: 0.8513
[INFO  16:54:12] epoch 8: train_acc: 0.8535 	 test_acc: 0.8607
[INFO  16:54:28] epoch 9: train_acc: 0.8635 	 test_acc: 0.8680
[INFO  16:54:31] Task accuracies: {
    "task1": 0.5568,
    "task2": 0.8673
}
[INFO  16:54:31] Mean task accuracy: 0.7120
[INFO  16:54:31] Training run_id 9 with learning_rate 0.0001, beta_1 -100,beta_2 0.01 and freeze False
[INFO  16:54:31] Start experiment with parametrization:
{
    "dataset": {
        "name": "perm_mnist",
        "kwargs": {
            "batch_size": 100,
            "num_tasks": 10
        }
    },
    "cl_method": "generative_replay",
    "criterion": "cross_entropy",
    "beta_1": -100,
    "beta_2": 0.01,
    "enc_dimensions": [
        784,
        200,
        200,
        100
    ],
    "dec_class_dimensions": [
        100,
        10
    ],
    "dec_rec_dimensions": [
        100,
        200,
        200,
        784
    ],
    "n_bottleneck": 100,
    "epochs": 10,
    "freeze": false,
    "learning_rate": 0.0001,
    "nonlinearity": "relu",
    "mult_mlp": false,
    "n_replay": 1000,
    "optimizer": "adam",
    "replay_weight": 0.999,
    "seed": null,
    "test_samples": 1,
    "vae_batch_size": 128,
    "vae_epochs": 10,
    "vae_lr": 0.005,
    "vae_n_gaussian": 100,
    "vae_n_hidden": 400,
    "model": "comparison_model",
    "log_dir": "",
    "task": "perm_mnist_vib"
}
[INFO  16:54:31] Starting training of task 1
[INFO  16:54:45] epoch 0: train_acc: 0.6846 	 test_acc: 0.8759
[INFO  16:54:58] epoch 1: train_acc: 0.8944 	 test_acc: 0.9125
[INFO  16:55:12] epoch 2: train_acc: 0.9191 	 test_acc: 0.9300
[INFO  16:55:26] epoch 3: train_acc: 0.9335 	 test_acc: 0.9401
[INFO  16:55:39] epoch 4: train_acc: 0.9434 	 test_acc: 0.9450
[INFO  16:55:53] epoch 5: train_acc: 0.9487 	 test_acc: 0.9498
[INFO  16:56:06] epoch 6: train_acc: 0.9547 	 test_acc: 0.9541
[INFO  16:56:19] epoch 7: train_acc: 0.9594 	 test_acc: 0.9572
[INFO  16:56:33] epoch 8: train_acc: 0.9630 	 test_acc: 0.9570
[INFO  16:56:46] epoch 9: train_acc: 0.9647 	 test_acc: 0.9619
[INFO  16:59:11] Task accuracies: {
    "task1": 0.9617,
    "task2": 0.0854
}
[INFO  16:59:11] Mean task accuracy: 0.9617
[INFO  16:59:11] Update replay buffer for generative replay.
[INFO  16:59:13] Starting training of task 2
[INFO  16:59:29] epoch 0: train_acc: 0.5348 	 test_acc: 0.7433
[INFO  16:59:45] epoch 1: train_acc: 0.7758 	 test_acc: 0.8146
[INFO  17:00:00] epoch 2: train_acc: 0.8246 	 test_acc: 0.8463
[INFO  17:00:16] epoch 3: train_acc: 0.8500 	 test_acc: 0.8609
[INFO  17:00:32] epoch 4: train_acc: 0.8678 	 test_acc: 0.8735
[INFO  17:00:47] epoch 5: train_acc: 0.8804 	 test_acc: 0.8858
[INFO  17:01:03] epoch 6: train_acc: 0.8909 	 test_acc: 0.8956
[INFO  17:01:19] epoch 7: train_acc: 0.8990 	 test_acc: 0.8988
[INFO  17:01:35] epoch 8: train_acc: 0.9060 	 test_acc: 0.9062
[INFO  17:01:50] epoch 9: train_acc: 0.9090 	 test_acc: 0.9105
[INFO  17:01:54] Task accuracies: {
    "task1": 0.9092,
    "task2": 0.9085
}
[INFO  17:01:54] Mean task accuracy: 0.9089
[INFO  17:01:54] Training run_id 10 with learning_rate 0.0001, beta_1 -100,beta_2 0.01 and freeze False
[INFO  17:01:54] Start experiment with parametrization:
{
    "dataset": {
        "name": "perm_mnist",
        "kwargs": {
            "batch_size": 100,
            "num_tasks": 10
        }
    },
    "cl_method": "generative_replay",
    "criterion": "cross_entropy",
    "beta_1": -100,
    "beta_2": 0.01,
    "enc_dimensions": [
        784,
        200,
        200,
        1000
    ],
    "dec_class_dimensions": [
        1000,
        10
    ],
    "dec_rec_dimensions": [
        1000,
        200,
        200,
        784
    ],
    "n_bottleneck": 1000,
    "epochs": 10,
    "freeze": false,
    "learning_rate": 0.0001,
    "nonlinearity": "relu",
    "mult_mlp": false,
    "n_replay": 1000,
    "optimizer": "adam",
    "replay_weight": 0.999,
    "seed": null,
    "test_samples": 1,
    "vae_batch_size": 128,
    "vae_epochs": 10,
    "vae_lr": 0.005,
    "vae_n_gaussian": 100,
    "vae_n_hidden": 400,
    "model": "vib_model",
    "log_dir": "",
    "task": "perm_mnist_vib"
}
[INFO  17:01:54] Starting training of task 1
[INFO  17:02:09] epoch 0: train_acc: 0.2047 	 test_acc: 0.4143
[INFO  17:02:24] epoch 1: train_acc: 0.6597 	 test_acc: 0.7802
[INFO  17:02:39] epoch 2: train_acc: 0.8053 	 test_acc: 0.8342
[INFO  17:02:55] epoch 3: train_acc: 0.8432 	 test_acc: 0.8600
[INFO  17:03:10] epoch 4: train_acc: 0.8657 	 test_acc: 0.8789
[INFO  17:03:25] epoch 5: train_acc: 0.8779 	 test_acc: 0.8845
[INFO  17:03:40] epoch 6: train_acc: 0.8834 	 test_acc: 0.8932
[INFO  17:03:55] epoch 7: train_acc: 0.8881 	 test_acc: 0.8972
[INFO  17:04:10] epoch 8: train_acc: 0.8925 	 test_acc: 0.8970
[INFO  17:04:26] epoch 9: train_acc: 0.8941 	 test_acc: 0.9021
[INFO  17:04:29] Task accuracies: {
    "task1": 0.9012,
    "task2": 0.0753
}
[INFO  17:04:29] Mean task accuracy: 0.9012
[INFO  17:04:29] Update replay buffer for generative replay.
[INFO  17:04:31] Starting training of task 2
[INFO  17:04:47] epoch 0: train_acc: 0.2634 	 test_acc: 0.5216
[INFO  17:05:02] epoch 1: train_acc: 0.6159 	 test_acc: 0.6918
[INFO  17:05:18] epoch 2: train_acc: 0.7342 	 test_acc: 0.7710
[INFO  17:05:34] epoch 3: train_acc: 0.7854 	 test_acc: 0.8142
[INFO  17:05:50] epoch 4: train_acc: 0.8203 	 test_acc: 0.8399
[INFO  17:06:05] epoch 5: train_acc: 0.8402 	 test_acc: 0.8569
[INFO  17:06:21] epoch 6: train_acc: 0.8614 	 test_acc: 0.8737
[INFO  17:06:37] epoch 7: train_acc: 0.8786 	 test_acc: 0.8900
[INFO  17:06:52] epoch 8: train_acc: 0.8919 	 test_acc: 0.9011
[INFO  17:07:08] epoch 9: train_acc: 0.9022 	 test_acc: 0.9101
[INFO  17:07:11] Task accuracies: {
    "task1": 0.4101,
    "task2": 0.9101
}
[INFO  17:07:11] Mean task accuracy: 0.6601
[INFO  17:07:11] Training run_id 11 with learning_rate 0.0001, beta_1 -100,beta_2 0.01 and freeze False
[INFO  17:07:12] Start experiment with parametrization:
{
    "dataset": {
        "name": "perm_mnist",
        "kwargs": {
            "batch_size": 100,
            "num_tasks": 10
        }
    },
    "cl_method": "generative_replay",
    "criterion": "cross_entropy",
    "beta_1": -100,
    "beta_2": 0.01,
    "enc_dimensions": [
        784,
        200,
        200,
        1000
    ],
    "dec_class_dimensions": [
        1000,
        10
    ],
    "dec_rec_dimensions": [
        1000,
        200,
        200,
        784
    ],
    "n_bottleneck": 1000,
    "epochs": 10,
    "freeze": false,
    "learning_rate": 0.0001,
    "nonlinearity": "relu",
    "mult_mlp": false,
    "n_replay": 1000,
    "optimizer": "adam",
    "replay_weight": 0.999,
    "seed": null,
    "test_samples": 1,
    "vae_batch_size": 128,
    "vae_epochs": 10,
    "vae_lr": 0.005,
    "vae_n_gaussian": 100,
    "vae_n_hidden": 400,
    "model": "comparison_model",
    "log_dir": "",
    "task": "perm_mnist_vib"
}
[INFO  17:07:12] Starting training of task 1
[INFO  17:07:26] epoch 0: train_acc: 0.7420 	 test_acc: 0.9025
[INFO  17:07:39] epoch 1: train_acc: 0.9166 	 test_acc: 0.9302
[INFO  17:07:53] epoch 2: train_acc: 0.9356 	 test_acc: 0.9408
[INFO  17:08:07] epoch 3: train_acc: 0.9486 	 test_acc: 0.9494
[INFO  17:08:20] epoch 4: train_acc: 0.9552 	 test_acc: 0.9533
[INFO  17:08:34] epoch 5: train_acc: 0.9606 	 test_acc: 0.9590
[INFO  17:08:48] epoch 6: train_acc: 0.9651 	 test_acc: 0.9578
[INFO  17:09:02] epoch 7: train_acc: 0.9684 	 test_acc: 0.9628
[INFO  17:09:15] epoch 8: train_acc: 0.9718 	 test_acc: 0.9636
[INFO  17:09:29] epoch 9: train_acc: 0.9730 	 test_acc: 0.9616
[INFO  17:11:54] Task accuracies: {
    "task1": 0.9652,
    "task2": 0.0927
}
[INFO  17:11:54] Mean task accuracy: 0.9652
[INFO  17:11:54] Update replay buffer for generative replay.
[INFO  17:11:57] Starting training of task 2
[INFO  17:12:12] epoch 0: train_acc: 0.6443 	 test_acc: 0.8017
[INFO  17:12:28] epoch 1: train_acc: 0.8213 	 test_acc: 0.8508
[INFO  17:12:44] epoch 2: train_acc: 0.8554 	 test_acc: 0.8726
[INFO  17:13:00] epoch 3: train_acc: 0.8734 	 test_acc: 0.8837
[INFO  17:13:16] epoch 4: train_acc: 0.8853 	 test_acc: 0.8887
[INFO  17:13:31] epoch 5: train_acc: 0.8941 	 test_acc: 0.8984
[INFO  17:13:47] epoch 6: train_acc: 0.8998 	 test_acc: 0.9058
[INFO  17:14:03] epoch 7: train_acc: 0.9046 	 test_acc: 0.9075
[INFO  17:14:19] epoch 8: train_acc: 0.9099 	 test_acc: 0.9110
[INFO  17:14:34] epoch 9: train_acc: 0.9127 	 test_acc: 0.9154
[INFO  17:14:38] Task accuracies: {
    "task1": 0.8789,
    "task2": 0.9127
}
[INFO  17:14:38] Mean task accuracy: 0.8958
[INFO  17:14:38] Training run_id 12 with learning_rate 0.0001, beta_1 -100,beta_2 0.1 and freeze False
[INFO  17:14:38] Start experiment with parametrization:
{
    "dataset": {
        "name": "perm_mnist",
        "kwargs": {
            "batch_size": 100,
            "num_tasks": 10
        }
    },
    "cl_method": "generative_replay",
    "criterion": "cross_entropy",
    "beta_1": -100,
    "beta_2": 0.1,
    "enc_dimensions": [
        784,
        200,
        200,
        10
    ],
    "dec_class_dimensions": [
        10,
        10
    ],
    "dec_rec_dimensions": [
        10,
        200,
        200,
        784
    ],
    "n_bottleneck": 10,
    "epochs": 10,
    "freeze": false,
    "learning_rate": 0.0001,
    "nonlinearity": "relu",
    "mult_mlp": false,
    "n_replay": 1000,
    "optimizer": "adam",
    "replay_weight": 0.999,
    "seed": null,
    "test_samples": 1,
    "vae_batch_size": 128,
    "vae_epochs": 10,
    "vae_lr": 0.005,
    "vae_n_gaussian": 100,
    "vae_n_hidden": 400,
    "model": "vib_model",
    "log_dir": "",
    "task": "perm_mnist_vib"
}
[INFO  17:14:38] Starting training of task 1
[INFO  17:14:53] epoch 0: train_acc: 0.0963 	 test_acc: 0.0900
[INFO  17:15:08] epoch 1: train_acc: 0.0554 	 test_acc: 0.0582
[INFO  17:15:23] epoch 2: train_acc: 0.1811 	 test_acc: 0.2968
[INFO  17:15:38] epoch 3: train_acc: 0.4111 	 test_acc: 0.4961
[INFO  17:15:53] epoch 4: train_acc: 0.5405 	 test_acc: 0.5861
[INFO  17:16:08] epoch 5: train_acc: 0.6299 	 test_acc: 0.6549
[INFO  17:16:23] epoch 6: train_acc: 0.6760 	 test_acc: 0.6870
[INFO  17:16:37] epoch 7: train_acc: 0.6968 	 test_acc: 0.7169
[INFO  17:16:52] epoch 8: train_acc: 0.7311 	 test_acc: 0.7615
[INFO  17:17:06] epoch 9: train_acc: 0.7641 	 test_acc: 0.7840
[INFO  17:17:09] Task accuracies: {
    "task1": 0.7836,
    "task2": 0.0892
}
[INFO  17:17:09] Mean task accuracy: 0.7836
[INFO  17:17:09] Update replay buffer for generative replay.
[INFO  17:17:10] Starting training of task 2
[INFO  17:17:25] epoch 0: train_acc: 0.1310 	 test_acc: 0.1992
[INFO  17:17:40] epoch 1: train_acc: 0.2450 	 test_acc: 0.3271
[INFO  17:17:54] epoch 2: train_acc: 0.3541 	 test_acc: 0.3647
[INFO  17:18:09] epoch 3: train_acc: 0.3479 	 test_acc: 0.3387
[INFO  17:18:23] epoch 4: train_acc: 0.3167 	 test_acc: 0.3024
[INFO  17:18:38] epoch 5: train_acc: 0.2804 	 test_acc: 0.2553
[INFO  17:18:53] epoch 6: train_acc: 0.2328 	 test_acc: 0.2193
[INFO  17:19:07] epoch 7: train_acc: 0.2018 	 test_acc: 0.1877
[INFO  17:19:22] epoch 8: train_acc: 0.1802 	 test_acc: 0.1779
[INFO  17:19:37] epoch 9: train_acc: 0.1672 	 test_acc: 0.1641
[INFO  17:19:40] Task accuracies: {
    "task1": 0.3314,
    "task2": 0.1661
}
[INFO  17:19:40] Mean task accuracy: 0.2488
[INFO  17:19:40] Training run_id 13 with learning_rate 0.0001, beta_1 -100,beta_2 0.1 and freeze False
[INFO  17:19:41] Start experiment with parametrization:
{
    "dataset": {
        "name": "perm_mnist",
        "kwargs": {
            "batch_size": 100,
            "num_tasks": 10
        }
    },
    "cl_method": "generative_replay",
    "criterion": "cross_entropy",
    "beta_1": -100,
    "beta_2": 0.1,
    "enc_dimensions": [
        784,
        200,
        200,
        10
    ],
    "dec_class_dimensions": [
        10,
        10
    ],
    "dec_rec_dimensions": [
        10,
        200,
        200,
        784
    ],
    "n_bottleneck": 10,
    "epochs": 10,
    "freeze": false,
    "learning_rate": 0.0001,
    "nonlinearity": "relu",
    "mult_mlp": false,
    "n_replay": 1000,
    "optimizer": "adam",
    "replay_weight": 0.999,
    "seed": null,
    "test_samples": 1,
    "vae_batch_size": 128,
    "vae_epochs": 10,
    "vae_lr": 0.005,
    "vae_n_gaussian": 100,
    "vae_n_hidden": 400,
    "model": "comparison_model",
    "log_dir": "",
    "task": "perm_mnist_vib"
}
[INFO  17:19:41] Starting training of task 1
[INFO  17:19:53] epoch 0: train_acc: 0.4666 	 test_acc: 0.6919
[INFO  17:20:06] epoch 1: train_acc: 0.7656 	 test_acc: 0.8248
[INFO  17:20:19] epoch 2: train_acc: 0.8385 	 test_acc: 0.8626
[INFO  17:20:32] epoch 3: train_acc: 0.8707 	 test_acc: 0.8810
[INFO  17:20:45] epoch 4: train_acc: 0.8889 	 test_acc: 0.8994
[INFO  17:20:58] epoch 5: train_acc: 0.9015 	 test_acc: 0.9118
[INFO  17:21:11] epoch 6: train_acc: 0.9134 	 test_acc: 0.9144
[INFO  17:21:25] epoch 7: train_acc: 0.9201 	 test_acc: 0.9145
[INFO  17:21:38] epoch 8: train_acc: 0.9255 	 test_acc: 0.9173
[INFO  17:21:52] epoch 9: train_acc: 0.9301 	 test_acc: 0.9245
[INFO  17:24:15] Task accuracies: {
    "task1": 0.9257,
    "task2": 0.1109
}
[INFO  17:24:15] Mean task accuracy: 0.9257
[INFO  17:24:15] Update replay buffer for generative replay.
[INFO  17:24:17] Starting training of task 2
[INFO  17:24:32] epoch 0: train_acc: 0.5409 	 test_acc: 0.7130
[INFO  17:24:48] epoch 1: train_acc: 0.7352 	 test_acc: 0.7658
[INFO  17:25:03] epoch 2: train_acc: 0.7759 	 test_acc: 0.7928
[INFO  17:25:19] epoch 3: train_acc: 0.7973 	 test_acc: 0.8076
[INFO  17:25:34] epoch 4: train_acc: 0.8090 	 test_acc: 0.8295
[INFO  17:25:50] epoch 5: train_acc: 0.8214 	 test_acc: 0.8248
[INFO  17:26:05] epoch 6: train_acc: 0.8270 	 test_acc: 0.8349
[INFO  17:26:20] epoch 7: train_acc: 0.8331 	 test_acc: 0.8482
[INFO  17:26:36] epoch 8: train_acc: 0.8406 	 test_acc: 0.8448
[INFO  17:26:51] epoch 9: train_acc: 0.8425 	 test_acc: 0.8539
[INFO  17:26:54] Task accuracies: {
    "task1": 0.8613,
    "task2": 0.8498
}
[INFO  17:26:54] Mean task accuracy: 0.8555
[INFO  17:26:54] Training run_id 14 with learning_rate 0.0001, beta_1 -100,beta_2 0.1 and freeze False
[INFO  17:26:55] Start experiment with parametrization:
{
    "dataset": {
        "name": "perm_mnist",
        "kwargs": {
            "batch_size": 100,
            "num_tasks": 10
        }
    },
    "cl_method": "generative_replay",
    "criterion": "cross_entropy",
    "beta_1": -100,
    "beta_2": 0.1,
    "enc_dimensions": [
        784,
        200,
        200,
        100
    ],
    "dec_class_dimensions": [
        100,
        10
    ],
    "dec_rec_dimensions": [
        100,
        200,
        200,
        784
    ],
    "n_bottleneck": 100,
    "epochs": 10,
    "freeze": false,
    "learning_rate": 0.0001,
    "nonlinearity": "relu",
    "mult_mlp": false,
    "n_replay": 1000,
    "optimizer": "adam",
    "replay_weight": 0.999,
    "seed": null,
    "test_samples": 1,
    "vae_batch_size": 128,
    "vae_epochs": 10,
    "vae_lr": 0.005,
    "vae_n_gaussian": 100,
    "vae_n_hidden": 400,
    "model": "vib_model",
    "log_dir": "",
    "task": "perm_mnist_vib"
}
[INFO  17:26:55] Starting training of task 1
[INFO  17:27:10] epoch 0: train_acc: 0.1460 	 test_acc: 0.2432
[INFO  17:27:24] epoch 1: train_acc: 0.4284 	 test_acc: 0.5920
[INFO  17:27:39] epoch 2: train_acc: 0.6766 	 test_acc: 0.7365
[INFO  17:27:54] epoch 3: train_acc: 0.7529 	 test_acc: 0.7846
[INFO  17:28:09] epoch 4: train_acc: 0.7911 	 test_acc: 0.8105
[INFO  17:28:24] epoch 5: train_acc: 0.8134 	 test_acc: 0.8339
[INFO  17:28:39] epoch 6: train_acc: 0.8392 	 test_acc: 0.8553
[INFO  17:28:53] epoch 7: train_acc: 0.8531 	 test_acc: 0.8628
[INFO  17:29:08] epoch 8: train_acc: 0.8605 	 test_acc: 0.8705
[INFO  17:29:23] epoch 9: train_acc: 0.8660 	 test_acc: 0.8752
[INFO  17:29:26] Task accuracies: {
    "task1": 0.8752,
    "task2": 0.0888
}
[INFO  17:29:26] Mean task accuracy: 0.8752
[INFO  17:29:26] Update replay buffer for generative replay.
[INFO  17:29:29] Starting training of task 2
[INFO  17:29:44] epoch 0: train_acc: 0.0997 	 test_acc: 0.1377
[INFO  17:29:59] epoch 1: train_acc: 0.1948 	 test_acc: 0.2500
[INFO  17:30:14] epoch 2: train_acc: 0.2593 	 test_acc: 0.2719
[INFO  17:30:29] epoch 3: train_acc: 0.2671 	 test_acc: 0.2699
[INFO  17:30:44] epoch 4: train_acc: 0.2643 	 test_acc: 0.2618
[INFO  17:30:59] epoch 5: train_acc: 0.2455 	 test_acc: 0.2282
[INFO  17:31:14] epoch 6: train_acc: 0.2165 	 test_acc: 0.2014
[INFO  17:31:29] epoch 7: train_acc: 0.1921 	 test_acc: 0.1813
[INFO  17:31:44] epoch 8: train_acc: 0.1714 	 test_acc: 0.1594
[INFO  17:31:59] epoch 9: train_acc: 0.1513 	 test_acc: 0.1439
[INFO  17:32:03] Task accuracies: {
    "task1": 0.412,
    "task2": 0.1464
}
[INFO  17:32:03] Mean task accuracy: 0.2792
[INFO  17:32:03] Training run_id 15 with learning_rate 0.0001, beta_1 -100,beta_2 0.1 and freeze False
[INFO  17:32:03] Start experiment with parametrization:
{
    "dataset": {
        "name": "perm_mnist",
        "kwargs": {
            "batch_size": 100,
            "num_tasks": 10
        }
    },
    "cl_method": "generative_replay",
    "criterion": "cross_entropy",
    "beta_1": -100,
    "beta_2": 0.1,
    "enc_dimensions": [
        784,
        200,
        200,
        100
    ],
    "dec_class_dimensions": [
        100,
        10
    ],
    "dec_rec_dimensions": [
        100,
        200,
        200,
        784
    ],
    "n_bottleneck": 100,
    "epochs": 10,
    "freeze": false,
    "learning_rate": 0.0001,
    "nonlinearity": "relu",
    "mult_mlp": false,
    "n_replay": 1000,
    "optimizer": "adam",
    "replay_weight": 0.999,
    "seed": null,
    "test_samples": 1,
    "vae_batch_size": 128,
    "vae_epochs": 10,
    "vae_lr": 0.005,
    "vae_n_gaussian": 100,
    "vae_n_hidden": 400,
    "model": "comparison_model",
    "log_dir": "",
    "task": "perm_mnist_vib"
}
[INFO  17:32:03] Starting training of task 1
[INFO  17:32:16] epoch 0: train_acc: 0.5720 	 test_acc: 0.7872
[INFO  17:32:30] epoch 1: train_acc: 0.8126 	 test_acc: 0.8417
[INFO  17:32:43] epoch 2: train_acc: 0.8495 	 test_acc: 0.8682
[INFO  17:32:57] epoch 3: train_acc: 0.8691 	 test_acc: 0.8767
[INFO  17:33:10] epoch 4: train_acc: 0.8808 	 test_acc: 0.8815
[INFO  17:33:23] epoch 5: train_acc: 0.8895 	 test_acc: 0.8900
[INFO  17:33:37] epoch 6: train_acc: 0.8919 	 test_acc: 0.9001
[INFO  17:33:50] epoch 7: train_acc: 0.8987 	 test_acc: 0.8919
[INFO  17:34:03] epoch 8: train_acc: 0.9001 	 test_acc: 0.8917
[INFO  17:34:17] epoch 9: train_acc: 0.9037 	 test_acc: 0.8993
[INFO  17:36:38] Task accuracies: {
    "task1": 0.9013,
    "task2": 0.0874
}
[INFO  17:36:38] Mean task accuracy: 0.9013
[INFO  17:36:38] Update replay buffer for generative replay.
[INFO  17:36:40] Starting training of task 2
[INFO  17:36:55] epoch 0: train_acc: 0.4667 	 test_acc: 0.6502
[INFO  17:37:11] epoch 1: train_acc: 0.6903 	 test_acc: 0.7279
[INFO  17:37:26] epoch 2: train_acc: 0.7361 	 test_acc: 0.7577
[INFO  17:37:41] epoch 3: train_acc: 0.7608 	 test_acc: 0.7750
[INFO  17:37:56] epoch 4: train_acc: 0.7737 	 test_acc: 0.7792
[INFO  17:38:12] epoch 5: train_acc: 0.7762 	 test_acc: 0.7841
[INFO  17:38:27] epoch 6: train_acc: 0.7755 	 test_acc: 0.7772
[INFO  17:38:42] epoch 7: train_acc: 0.7667 	 test_acc: 0.7642
[INFO  17:38:57] epoch 8: train_acc: 0.7635 	 test_acc: 0.7639
[INFO  17:39:13] epoch 9: train_acc: 0.7551 	 test_acc: 0.7472
[INFO  17:39:16] Task accuracies: {
    "task1": 0.7499,
    "task2": 0.7554
}
[INFO  17:39:16] Mean task accuracy: 0.7527
[INFO  17:39:16] Training run_id 16 with learning_rate 0.0001, beta_1 -100,beta_2 0.1 and freeze False
[INFO  17:39:16] Start experiment with parametrization:
{
    "dataset": {
        "name": "perm_mnist",
        "kwargs": {
            "batch_size": 100,
            "num_tasks": 10
        }
    },
    "cl_method": "generative_replay",
    "criterion": "cross_entropy",
    "beta_1": -100,
    "beta_2": 0.1,
    "enc_dimensions": [
        784,
        200,
        200,
        1000
    ],
    "dec_class_dimensions": [
        1000,
        10
    ],
    "dec_rec_dimensions": [
        1000,
        200,
        200,
        784
    ],
    "n_bottleneck": 1000,
    "epochs": 10,
    "freeze": false,
    "learning_rate": 0.0001,
    "nonlinearity": "relu",
    "mult_mlp": false,
    "n_replay": 1000,
    "optimizer": "adam",
    "replay_weight": 0.999,
    "seed": null,
    "test_samples": 1,
    "vae_batch_size": 128,
    "vae_epochs": 10,
    "vae_lr": 0.005,
    "vae_n_gaussian": 100,
    "vae_n_hidden": 400,
    "model": "vib_model",
    "log_dir": "",
    "task": "perm_mnist_vib"
}
[INFO  17:39:16] Starting training of task 1
[INFO  17:39:31] epoch 0: train_acc: 0.2014 	 test_acc: 0.3912
[INFO  17:39:46] epoch 1: train_acc: 0.6505 	 test_acc: 0.7802
[INFO  17:40:00] epoch 2: train_acc: 0.7971 	 test_acc: 0.8225
[INFO  17:40:15] epoch 3: train_acc: 0.8376 	 test_acc: 0.8636
[INFO  17:40:30] epoch 4: train_acc: 0.8624 	 test_acc: 0.8748
[INFO  17:40:45] epoch 5: train_acc: 0.8718 	 test_acc: 0.8838
[INFO  17:41:00] epoch 6: train_acc: 0.8781 	 test_acc: 0.8876
[INFO  17:41:14] epoch 7: train_acc: 0.8845 	 test_acc: 0.8933
[INFO  17:41:29] epoch 8: train_acc: 0.8885 	 test_acc: 0.8985
[INFO  17:41:44] epoch 9: train_acc: 0.8903 	 test_acc: 0.8992
[INFO  17:41:48] Task accuracies: {
    "task1": 0.899,
    "task2": 0.0943
}
[INFO  17:41:48] Mean task accuracy: 0.8990
[INFO  17:41:48] Update replay buffer for generative replay.
[INFO  17:41:49] Starting training of task 2
[INFO  17:42:05] epoch 0: train_acc: 0.1226 	 test_acc: 0.1512
[INFO  17:42:20] epoch 1: train_acc: 0.1709 	 test_acc: 0.1887
[INFO  17:42:35] epoch 2: train_acc: 0.2098 	 test_acc: 0.2160
[INFO  17:42:50] epoch 3: train_acc: 0.1986 	 test_acc: 0.1884
[INFO  17:43:05] epoch 4: train_acc: 0.1692 	 test_acc: 0.1556
[INFO  17:43:20] epoch 5: train_acc: 0.1466 	 test_acc: 0.1383
[INFO  17:43:35] epoch 6: train_acc: 0.1313 	 test_acc: 0.1280
[INFO  17:43:50] epoch 7: train_acc: 0.1283 	 test_acc: 0.1231
[INFO  17:44:05] epoch 8: train_acc: 0.1206 	 test_acc: 0.1236
[INFO  17:44:20] epoch 9: train_acc: 0.1206 	 test_acc: 0.1198
[INFO  17:44:23] Task accuracies: {
    "task1": 0.2779,
    "task2": 0.1231
}
[INFO  17:44:23] Mean task accuracy: 0.2005
[INFO  17:44:23] Training run_id 17 with learning_rate 0.0001, beta_1 -100,beta_2 0.1 and freeze False
[INFO  17:44:23] Start experiment with parametrization:
{
    "dataset": {
        "name": "perm_mnist",
        "kwargs": {
            "batch_size": 100,
            "num_tasks": 10
        }
    },
    "cl_method": "generative_replay",
    "criterion": "cross_entropy",
    "beta_1": -100,
    "beta_2": 0.1,
    "enc_dimensions": [
        784,
        200,
        200,
        1000
    ],
    "dec_class_dimensions": [
        1000,
        10
    ],
    "dec_rec_dimensions": [
        1000,
        200,
        200,
        784
    ],
    "n_bottleneck": 1000,
    "epochs": 10,
    "freeze": false,
    "learning_rate": 0.0001,
    "nonlinearity": "relu",
    "mult_mlp": false,
    "n_replay": 1000,
    "optimizer": "adam",
    "replay_weight": 0.999,
    "seed": null,
    "test_samples": 1,
    "vae_batch_size": 128,
    "vae_epochs": 10,
    "vae_lr": 0.005,
    "vae_n_gaussian": 100,
    "vae_n_hidden": 400,
    "model": "comparison_model",
    "log_dir": "",
    "task": "perm_mnist_vib"
}
[INFO  17:44:23] Starting training of task 1
[INFO  17:44:36] epoch 0: train_acc: 0.6045 	 test_acc: 0.8350
[INFO  17:44:49] epoch 1: train_acc: 0.8501 	 test_acc: 0.8710
[INFO  17:45:02] epoch 2: train_acc: 0.8756 	 test_acc: 0.8837
[INFO  17:45:15] epoch 3: train_acc: 0.8898 	 test_acc: 0.8849
[INFO  17:45:29] epoch 4: train_acc: 0.8933 	 test_acc: 0.8941
[INFO  17:45:42] epoch 5: train_acc: 0.8976 	 test_acc: 0.8975
[INFO  17:45:55] epoch 6: train_acc: 0.8999 	 test_acc: 0.8974
[INFO  17:46:08] epoch 7: train_acc: 0.9029 	 test_acc: 0.8956
[INFO  17:46:21] epoch 8: train_acc: 0.9050 	 test_acc: 0.8992
[INFO  17:46:34] epoch 9: train_acc: 0.9079 	 test_acc: 0.8923
[INFO  17:48:53] Task accuracies: {
    "task1": 0.8937,
    "task2": 0.0978
}
[INFO  17:48:53] Mean task accuracy: 0.8937
[INFO  17:48:53] Update replay buffer for generative replay.
[INFO  17:48:55] Starting training of task 2
[INFO  17:49:10] epoch 0: train_acc: 0.5858 	 test_acc: 0.7159
[INFO  17:49:25] epoch 1: train_acc: 0.7347 	 test_acc: 0.7590
[INFO  17:49:40] epoch 2: train_acc: 0.7697 	 test_acc: 0.7799
[INFO  17:49:55] epoch 3: train_acc: 0.7853 	 test_acc: 0.7911
[INFO  17:50:10] epoch 4: train_acc: 0.7818 	 test_acc: 0.7820
[INFO  17:50:25] epoch 5: train_acc: 0.7635 	 test_acc: 0.7549
[INFO  17:50:40] epoch 6: train_acc: 0.7281 	 test_acc: 0.6976
[INFO  17:50:55] epoch 7: train_acc: 0.6663 	 test_acc: 0.6269
[INFO  17:51:10] epoch 8: train_acc: 0.6024 	 test_acc: 0.5746
[INFO  17:51:25] epoch 9: train_acc: 0.5616 	 test_acc: 0.5461
[INFO  17:51:28] Task accuracies: {
    "task1": 0.5578,
    "task2": 0.5449
}
[INFO  17:51:28] Mean task accuracy: 0.5513
[INFO  17:51:28] Training run_id 18 with learning_rate 0.0001, beta_1 -100,beta_2 1 and freeze False
[INFO  17:51:28] Start experiment with parametrization:
{
    "dataset": {
        "name": "perm_mnist",
        "kwargs": {
            "batch_size": 100,
            "num_tasks": 10
        }
    },
    "cl_method": "generative_replay",
    "criterion": "cross_entropy",
    "beta_1": -100,
    "beta_2": 1,
    "enc_dimensions": [
        784,
        200,
        200,
        10
    ],
    "dec_class_dimensions": [
        10,
        10
    ],
    "dec_rec_dimensions": [
        10,
        200,
        200,
        784
    ],
    "n_bottleneck": 10,
    "epochs": 10,
    "freeze": false,
    "learning_rate": 0.0001,
    "nonlinearity": "relu",
    "mult_mlp": false,
    "n_replay": 1000,
    "optimizer": "adam",
    "replay_weight": 0.999,
    "seed": null,
    "test_samples": 1,
    "vae_batch_size": 128,
    "vae_epochs": 10,
    "vae_lr": 0.005,
    "vae_n_gaussian": 100,
    "vae_n_hidden": 400,
    "model": "vib_model",
    "log_dir": "",
    "task": "perm_mnist_vib"
}
[INFO  17:51:28] Starting training of task 1
[INFO  17:51:43] epoch 0: train_acc: 0.0943 	 test_acc: 0.0552
[INFO  17:51:57] epoch 1: train_acc: 0.0993 	 test_acc: 0.2041
[INFO  17:52:11] epoch 2: train_acc: 0.2833 	 test_acc: 0.3751
[INFO  17:52:26] epoch 3: train_acc: 0.4437 	 test_acc: 0.5071
[INFO  17:52:40] epoch 4: train_acc: 0.5623 	 test_acc: 0.6086
[INFO  17:52:55] epoch 5: train_acc: 0.6381 	 test_acc: 0.6643
[INFO  17:53:09] epoch 6: train_acc: 0.6808 	 test_acc: 0.7143
[INFO  17:53:24] epoch 7: train_acc: 0.7264 	 test_acc: 0.7550
[INFO  17:53:38] epoch 8: train_acc: 0.7592 	 test_acc: 0.7828
[INFO  17:53:53] epoch 9: train_acc: 0.7814 	 test_acc: 0.8032
[INFO  17:53:56] Task accuracies: {
    "task1": 0.8042,
    "task2": 0.1072
}
[INFO  17:53:56] Mean task accuracy: 0.8042
[INFO  17:53:56] Update replay buffer for generative replay.
[INFO  17:53:58] Starting training of task 2
[INFO  17:54:13] epoch 0: train_acc: 0.1100 	 test_acc: 0.1185
[INFO  17:54:28] epoch 1: train_acc: 0.1109 	 test_acc: 0.1090
[INFO  17:54:43] epoch 2: train_acc: 0.1079 	 test_acc: 0.1077
[INFO  17:54:58] epoch 3: train_acc: 0.1084 	 test_acc: 0.1119
[INFO  17:55:13] epoch 4: train_acc: 0.1071 	 test_acc: 0.1078
[INFO  17:55:28] epoch 5: train_acc: 0.1058 	 test_acc: 0.1047
[INFO  17:55:43] epoch 6: train_acc: 0.1048 	 test_acc: 0.1026
[INFO  17:55:58] epoch 7: train_acc: 0.1038 	 test_acc: 0.1035
[INFO  17:56:13] epoch 8: train_acc: 0.1036 	 test_acc: 0.1033
[INFO  17:56:28] epoch 9: train_acc: 0.1029 	 test_acc: 0.1003
[INFO  17:56:31] Task accuracies: {
    "task1": 0.1088,
    "task2": 0.1009
}
[INFO  17:56:31] Mean task accuracy: 0.1049
[INFO  17:56:31] Training run_id 19 with learning_rate 0.0001, beta_1 -100,beta_2 1 and freeze False
[INFO  17:56:32] Start experiment with parametrization:
{
    "dataset": {
        "name": "perm_mnist",
        "kwargs": {
            "batch_size": 100,
            "num_tasks": 10
        }
    },
    "cl_method": "generative_replay",
    "criterion": "cross_entropy",
    "beta_1": -100,
    "beta_2": 1,
    "enc_dimensions": [
        784,
        200,
        200,
        10
    ],
    "dec_class_dimensions": [
        10,
        10
    ],
    "dec_rec_dimensions": [
        10,
        200,
        200,
        784
    ],
    "n_bottleneck": 10,
    "epochs": 10,
    "freeze": false,
    "learning_rate": 0.0001,
    "nonlinearity": "relu",
    "mult_mlp": false,
    "n_replay": 1000,
    "optimizer": "adam",
    "replay_weight": 0.999,
    "seed": null,
    "test_samples": 1,
    "vae_batch_size": 128,
    "vae_epochs": 10,
    "vae_lr": 0.005,
    "vae_n_gaussian": 100,
    "vae_n_hidden": 400,
    "model": "comparison_model",
    "log_dir": "",
    "task": "perm_mnist_vib"
}
[INFO  17:56:32] Starting training of task 1
[INFO  17:56:45] epoch 0: train_acc: 0.1548 	 test_acc: 0.1755
[INFO  17:56:58] epoch 1: train_acc: 0.1777 	 test_acc: 0.1787
[INFO  17:57:11] epoch 2: train_acc: 0.1825 	 test_acc: 0.1806
[INFO  17:57:25] epoch 3: train_acc: 0.1833 	 test_acc: 0.1855
[INFO  17:57:38] epoch 4: train_acc: 0.1865 	 test_acc: 0.1820
[INFO  17:57:52] epoch 5: train_acc: 0.1841 	 test_acc: 0.1862
[INFO  17:58:06] epoch 6: train_acc: 0.1819 	 test_acc: 0.1748
[INFO  17:58:20] epoch 7: train_acc: 0.1841 	 test_acc: 0.1774
[INFO  17:58:33] epoch 8: train_acc: 0.1857 	 test_acc: 0.1836
[INFO  17:58:47] epoch 9: train_acc: 0.1848 	 test_acc: 0.1835
[INFO  18:01:13] Task accuracies: {
    "task1": 0.1856,
    "task2": 0.1041
}
[INFO  18:01:13] Mean task accuracy: 0.1856
[INFO  18:01:13] Update replay buffer for generative replay.
[INFO  18:01:15] Starting training of task 2
[INFO  18:01:31] epoch 0: train_acc: 0.1409 	 test_acc: 0.1499
[INFO  18:01:47] epoch 1: train_acc: 0.1474 	 test_acc: 0.1418
[INFO  18:02:02] epoch 2: train_acc: 0.1393 	 test_acc: 0.1332
[INFO  18:02:19] epoch 3: train_acc: 0.1288 	 test_acc: 0.1275
[INFO  18:02:35] epoch 4: train_acc: 0.1197 	 test_acc: 0.1238
[INFO  18:02:51] epoch 5: train_acc: 0.1152 	 test_acc: 0.1171
[INFO  18:03:07] epoch 6: train_acc: 0.1123 	 test_acc: 0.1100
[INFO  18:03:23] epoch 7: train_acc: 0.1064 	 test_acc: 0.1043
[INFO  18:03:39] epoch 8: train_acc: 0.1051 	 test_acc: 0.1037
[INFO  18:03:55] epoch 9: train_acc: 0.1035 	 test_acc: 0.1008
[INFO  18:03:58] Task accuracies: {
    "task1": 0.1015,
    "task2": 0.1013
}
[INFO  18:03:58] Mean task accuracy: 0.1014
[INFO  18:03:58] Training run_id 20 with learning_rate 0.0001, beta_1 -100,beta_2 1 and freeze False
[INFO  18:03:59] Start experiment with parametrization:
{
    "dataset": {
        "name": "perm_mnist",
        "kwargs": {
            "batch_size": 100,
            "num_tasks": 10
        }
    },
    "cl_method": "generative_replay",
    "criterion": "cross_entropy",
    "beta_1": -100,
    "beta_2": 1,
    "enc_dimensions": [
        784,
        200,
        200,
        100
    ],
    "dec_class_dimensions": [
        100,
        10
    ],
    "dec_rec_dimensions": [
        100,
        200,
        200,
        784
    ],
    "n_bottleneck": 100,
    "epochs": 10,
    "freeze": false,
    "learning_rate": 0.0001,
    "nonlinearity": "relu",
    "mult_mlp": false,
    "n_replay": 1000,
    "optimizer": "adam",
    "replay_weight": 0.999,
    "seed": null,
    "test_samples": 1,
    "vae_batch_size": 128,
    "vae_epochs": 10,
    "vae_lr": 0.005,
    "vae_n_gaussian": 100,
    "vae_n_hidden": 400,
    "model": "vib_model",
    "log_dir": "",
    "task": "perm_mnist_vib"
}
[INFO  18:03:59] Starting training of task 1
[INFO  18:04:14] epoch 0: train_acc: 0.1290 	 test_acc: 0.1946
[INFO  18:04:30] epoch 1: train_acc: 0.3878 	 test_acc: 0.5757
[INFO  18:04:45] epoch 2: train_acc: 0.6734 	 test_acc: 0.7470
[INFO  18:05:01] epoch 3: train_acc: 0.7608 	 test_acc: 0.7870
[INFO  18:05:16] epoch 4: train_acc: 0.7958 	 test_acc: 0.8143
[INFO  18:05:32] epoch 5: train_acc: 0.8196 	 test_acc: 0.8377
[INFO  18:05:47] epoch 6: train_acc: 0.8468 	 test_acc: 0.8612
[INFO  18:06:03] epoch 7: train_acc: 0.8617 	 test_acc: 0.8694
[INFO  18:06:19] epoch 8: train_acc: 0.8673 	 test_acc: 0.8752
[INFO  18:06:34] epoch 9: train_acc: 0.8722 	 test_acc: 0.8772
[INFO  18:06:38] Task accuracies: {
    "task1": 0.8797,
    "task2": 0.1194
}
[INFO  18:06:38] Mean task accuracy: 0.8797
[INFO  18:06:38] Update replay buffer for generative replay.
/cluster/home/leoniem/compressed_replay/lib/utils.py:188: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig = plt.figure(figsize=(25, 8))
[INFO  18:06:40] Starting training of task 2
[INFO  18:06:56] epoch 0: train_acc: 0.0971 	 test_acc: 0.0951
[INFO  18:07:12] epoch 1: train_acc: 0.0990 	 test_acc: 0.0986
[INFO  18:07:28] epoch 2: train_acc: 0.1001 	 test_acc: 0.0967
[INFO  18:07:44] epoch 3: train_acc: 0.1010 	 test_acc: 0.1013
[INFO  18:08:00] epoch 4: train_acc: 0.1003 	 test_acc: 0.0996
[INFO  18:08:16] epoch 5: train_acc: 0.1013 	 test_acc: 0.1010
[INFO  18:08:32] epoch 6: train_acc: 0.1007 	 test_acc: 0.0960
[INFO  18:08:48] epoch 7: train_acc: 0.0993 	 test_acc: 0.1014
[INFO  18:09:04] epoch 8: train_acc: 0.0962 	 test_acc: 0.0942
[INFO  18:09:20] epoch 9: train_acc: 0.0942 	 test_acc: 0.0927
[INFO  18:09:24] Task accuracies: {
    "task1": 0.131,
    "task2": 0.0934
}
[INFO  18:09:24] Mean task accuracy: 0.1122
[INFO  18:09:24] Training run_id 21 with learning_rate 0.0001, beta_1 -100,beta_2 1 and freeze False
[INFO  18:09:24] Start experiment with parametrization:
{
    "dataset": {
        "name": "perm_mnist",
        "kwargs": {
            "batch_size": 100,
            "num_tasks": 10
        }
    },
    "cl_method": "generative_replay",
    "criterion": "cross_entropy",
    "beta_1": -100,
    "beta_2": 1,
    "enc_dimensions": [
        784,
        200,
        200,
        100
    ],
    "dec_class_dimensions": [
        100,
        10
    ],
    "dec_rec_dimensions": [
        100,
        200,
        200,
        784
    ],
    "n_bottleneck": 100,
    "epochs": 10,
    "freeze": false,
    "learning_rate": 0.0001,
    "nonlinearity": "relu",
    "mult_mlp": false,
    "n_replay": 1000,
    "optimizer": "adam",
    "replay_weight": 0.999,
    "seed": null,
    "test_samples": 1,
    "vae_batch_size": 128,
    "vae_epochs": 10,
    "vae_lr": 0.005,
    "vae_n_gaussian": 100,
    "vae_n_hidden": 400,
    "model": "comparison_model",
    "log_dir": "",
    "task": "perm_mnist_vib"
}
[INFO  18:09:24] Starting training of task 1
[INFO  18:09:38] epoch 0: train_acc: 0.1550 	 test_acc: 0.1892
[INFO  18:09:53] epoch 1: train_acc: 0.1795 	 test_acc: 0.1847
[INFO  18:10:07] epoch 2: train_acc: 0.1863 	 test_acc: 0.1752
[INFO  18:10:21] epoch 3: train_acc: 0.1862 	 test_acc: 0.1817
[INFO  18:10:35] epoch 4: train_acc: 0.1845 	 test_acc: 0.1825
[INFO  18:10:49] epoch 5: train_acc: 0.1840 	 test_acc: 0.1857
[INFO  18:11:03] epoch 6: train_acc: 0.1785 	 test_acc: 0.1861
[INFO  18:11:18] epoch 7: train_acc: 0.1836 	 test_acc: 0.1823
[INFO  18:11:32] epoch 8: train_acc: 0.1838 	 test_acc: 0.1811
[INFO  18:11:46] epoch 9: train_acc: 0.1787 	 test_acc: 0.1851
[INFO  18:14:16] Task accuracies: {
    "task1": 0.1677,
    "task2": 0.0975
}
[INFO  18:14:16] Mean task accuracy: 0.1677
[INFO  18:14:16] Update replay buffer for generative replay.
[INFO  18:14:18] Starting training of task 2
[INFO  18:14:34] epoch 0: train_acc: 0.1380 	 test_acc: 0.1447
[INFO  18:14:50] epoch 1: train_acc: 0.1384 	 test_acc: 0.1399
[INFO  18:15:06] epoch 2: train_acc: 0.1328 	 test_acc: 0.1312
[INFO  18:15:23] epoch 3: train_acc: 0.1207 	 test_acc: 0.1190
[INFO  18:15:39] epoch 4: train_acc: 0.1138 	 test_acc: 0.1142
[INFO  18:15:55] epoch 5: train_acc: 0.1125 	 test_acc: 0.1151
[INFO  18:16:11] epoch 6: train_acc: 0.1124 	 test_acc: 0.1131
[INFO  18:16:27] epoch 7: train_acc: 0.1124 	 test_acc: 0.1135
[INFO  18:16:43] epoch 8: train_acc: 0.1124 	 test_acc: 0.1135
[INFO  18:16:59] epoch 9: train_acc: 0.1124 	 test_acc: 0.1134
[INFO  18:17:03] Task accuracies: {
    "task1": 0.1135,
    "task2": 0.1136
}
[INFO  18:17:03] Mean task accuracy: 0.1135
[INFO  18:17:03] Training run_id 22 with learning_rate 0.0001, beta_1 -100,beta_2 1 and freeze False
[INFO  18:17:03] Start experiment with parametrization:
{
    "dataset": {
        "name": "perm_mnist",
        "kwargs": {
            "batch_size": 100,
            "num_tasks": 10
        }
    },
    "cl_method": "generative_replay",
    "criterion": "cross_entropy",
    "beta_1": -100,
    "beta_2": 1,
    "enc_dimensions": [
        784,
        200,
        200,
        1000
    ],
    "dec_class_dimensions": [
        1000,
        10
    ],
    "dec_rec_dimensions": [
        1000,
        200,
        200,
        784
    ],
    "n_bottleneck": 1000,
    "epochs": 10,
    "freeze": false,
    "learning_rate": 0.0001,
    "nonlinearity": "relu",
    "mult_mlp": false,
    "n_replay": 1000,
    "optimizer": "adam",
    "replay_weight": 0.999,
    "seed": null,
    "test_samples": 1,
    "vae_batch_size": 128,
    "vae_epochs": 10,
    "vae_lr": 0.005,
    "vae_n_gaussian": 100,
    "vae_n_hidden": 400,
    "model": "vib_model",
    "log_dir": "",
    "task": "perm_mnist_vib"
}
[INFO  18:17:03] Starting training of task 1
[INFO  18:17:19] epoch 0: train_acc: 0.2006 	 test_acc: 0.4399
[INFO  18:17:34] epoch 1: train_acc: 0.6300 	 test_acc: 0.7537
[INFO  18:17:50] epoch 2: train_acc: 0.7726 	 test_acc: 0.8023
[INFO  18:18:05] epoch 3: train_acc: 0.8188 	 test_acc: 0.8370
[INFO  18:18:21] epoch 4: train_acc: 0.8462 	 test_acc: 0.8596
[INFO  18:18:37] epoch 5: train_acc: 0.8621 	 test_acc: 0.8748
[INFO  18:18:52] epoch 6: train_acc: 0.8700 	 test_acc: 0.8794
[INFO  18:19:08] epoch 7: train_acc: 0.8726 	 test_acc: 0.8811
[INFO  18:19:24] epoch 8: train_acc: 0.8762 	 test_acc: 0.8850
[INFO  18:19:39] epoch 9: train_acc: 0.8772 	 test_acc: 0.8850
[INFO  18:19:43] Task accuracies: {
    "task1": 0.8857,
    "task2": 0.0965
}
[INFO  18:19:43] Mean task accuracy: 0.8857
[INFO  18:19:43] Update replay buffer for generative replay.
[INFO  18:19:45] Starting training of task 2
[INFO  18:20:01] epoch 0: train_acc: 0.0978 	 test_acc: 0.1001
[INFO  18:20:17] epoch 1: train_acc: 0.0993 	 test_acc: 0.0924
[INFO  18:20:33] epoch 2: train_acc: 0.0966 	 test_acc: 0.0926
[INFO  18:20:48] epoch 3: train_acc: 0.0964 	 test_acc: 0.0958
[INFO  18:21:04] epoch 4: train_acc: 0.0988 	 test_acc: 0.1013
[INFO  18:21:19] epoch 5: train_acc: 0.0958 	 test_acc: 0.0989
[INFO  18:21:34] epoch 6: train_acc: 0.0961 	 test_acc: 0.1001
[INFO  18:21:49] epoch 7: train_acc: 0.0979 	 test_acc: 0.1028
[INFO  18:22:04] epoch 8: train_acc: 0.1018 	 test_acc: 0.1000
[INFO  18:22:18] epoch 9: train_acc: 0.0984 	 test_acc: 0.0982
[INFO  18:22:21] Task accuracies: {
    "task1": 0.1255,
    "task2": 0.1061
}
[INFO  18:22:21] Mean task accuracy: 0.1158
[INFO  18:22:21] Training run_id 23 with learning_rate 0.0001, beta_1 -100,beta_2 1 and freeze False
[INFO  18:22:22] Start experiment with parametrization:
{
    "dataset": {
        "name": "perm_mnist",
        "kwargs": {
            "batch_size": 100,
            "num_tasks": 10
        }
    },
    "cl_method": "generative_replay",
    "criterion": "cross_entropy",
    "beta_1": -100,
    "beta_2": 1,
    "enc_dimensions": [
        784,
        200,
        200,
        1000
    ],
    "dec_class_dimensions": [
        1000,
        10
    ],
    "dec_rec_dimensions": [
        1000,
        200,
        200,
        784
    ],
    "n_bottleneck": 1000,
    "epochs": 10,
    "freeze": false,
    "learning_rate": 0.0001,
    "nonlinearity": "relu",
    "mult_mlp": false,
    "n_replay": 1000,
    "optimizer": "adam",
    "replay_weight": 0.999,
    "seed": null,
    "test_samples": 1,
    "vae_batch_size": 128,
    "vae_epochs": 10,
    "vae_lr": 0.005,
    "vae_n_gaussian": 100,
    "vae_n_hidden": 400,
    "model": "comparison_model",
    "log_dir": "",
    "task": "perm_mnist_vib"
}
[INFO  18:22:22] Starting training of task 1
[INFO  18:22:35] epoch 0: train_acc: 0.1105 	 test_acc: 0.1255
[INFO  18:22:47] epoch 1: train_acc: 0.1465 	 test_acc: 0.1554
[INFO  18:23:00] epoch 2: train_acc: 0.1636 	 test_acc: 0.1658
[INFO  18:23:13] epoch 3: train_acc: 0.1697 	 test_acc: 0.1677
[INFO  18:23:26] epoch 4: train_acc: 0.1691 	 test_acc: 0.1726
[INFO  18:23:39] epoch 5: train_acc: 0.1719 	 test_acc: 0.1716
[INFO  18:23:52] epoch 6: train_acc: 0.1706 	 test_acc: 0.1688
[INFO  18:24:05] epoch 7: train_acc: 0.1707 	 test_acc: 0.1739
[INFO  18:24:18] epoch 8: train_acc: 0.1727 	 test_acc: 0.1746
[INFO  18:24:30] epoch 9: train_acc: 0.1747 	 test_acc: 0.1758
[INFO  18:26:50] Task accuracies: {
    "task1": 0.1747,
    "task2": 0.1079
}
[INFO  18:26:50] Mean task accuracy: 0.1747
[INFO  18:26:50] Update replay buffer for generative replay.
[INFO  18:26:52] Starting training of task 2
[INFO  18:27:08] epoch 0: train_acc: 0.1369 	 test_acc: 0.1370
[INFO  18:27:23] epoch 1: train_acc: 0.1383 	 test_acc: 0.1338
[INFO  18:27:38] epoch 2: train_acc: 0.1272 	 test_acc: 0.1177
[INFO  18:27:53] epoch 3: train_acc: 0.1181 	 test_acc: 0.1129
[INFO  18:28:08] epoch 4: train_acc: 0.1126 	 test_acc: 0.1113
[INFO  18:28:23] epoch 5: train_acc: 0.1127 	 test_acc: 0.1074
[INFO  18:28:38] epoch 6: train_acc: 0.1130 	 test_acc: 0.1129
[INFO  18:28:53] epoch 7: train_acc: 0.1104 	 test_acc: 0.1100
[INFO  18:29:08] epoch 8: train_acc: 0.1094 	 test_acc: 0.1129
[INFO  18:29:23] epoch 9: train_acc: 0.1110 	 test_acc: 0.1105
[INFO  18:29:26] Task accuracies: {
    "task1": 0.108,
    "task2": 0.107
}
[INFO  18:29:26] Mean task accuracy: 0.1075
[INFO  18:29:26] Training run_id 24 with learning_rate 0.0001, beta_1 -100,beta_2 10 and freeze False
[INFO  18:29:26] Start experiment with parametrization:
{
    "dataset": {
        "name": "perm_mnist",
        "kwargs": {
            "batch_size": 100,
            "num_tasks": 10
        }
    },
    "cl_method": "generative_replay",
    "criterion": "cross_entropy",
    "beta_1": -100,
    "beta_2": 10,
    "enc_dimensions": [
        784,
        200,
        200,
        10
    ],
    "dec_class_dimensions": [
        10,
        10
    ],
    "dec_rec_dimensions": [
        10,
        200,
        200,
        784
    ],
    "n_bottleneck": 10,
    "epochs": 10,
    "freeze": false,
    "learning_rate": 0.0001,
    "nonlinearity": "relu",
    "mult_mlp": false,
    "n_replay": 1000,
    "optimizer": "adam",
    "replay_weight": 0.999,
    "seed": null,
    "test_samples": 1,
    "vae_batch_size": 128,
    "vae_epochs": 10,
    "vae_lr": 0.005,
    "vae_n_gaussian": 100,
    "vae_n_hidden": 400,
    "model": "vib_model",
    "log_dir": "",
    "task": "perm_mnist_vib"
}
[INFO  18:29:26] Starting training of task 1
[INFO  18:29:41] epoch 0: train_acc: 0.0975 	 test_acc: 0.1271
[INFO  18:29:56] epoch 1: train_acc: 0.2158 	 test_acc: 0.2919
[INFO  18:30:10] epoch 2: train_acc: 0.3293 	 test_acc: 0.3915
[INFO  18:30:25] epoch 3: train_acc: 0.4322 	 test_acc: 0.5203
[INFO  18:30:39] epoch 4: train_acc: 0.5556 	 test_acc: 0.6224
[INFO  18:30:54] epoch 5: train_acc: 0.6415 	 test_acc: 0.6871
[INFO  18:31:08] epoch 6: train_acc: 0.7021 	 test_acc: 0.7389
[INFO  18:31:23] epoch 7: train_acc: 0.7415 	 test_acc: 0.7687
[INFO  18:31:37] epoch 8: train_acc: 0.7674 	 test_acc: 0.7900
[INFO  18:31:52] epoch 9: train_acc: 0.7853 	 test_acc: 0.8010
[INFO  18:31:55] Task accuracies: {
    "task1": 0.8015,
    "task2": 0.1289
}
[INFO  18:31:55] Mean task accuracy: 0.8015
[INFO  18:31:55] Update replay buffer for generative replay.
[INFO  18:31:57] Starting training of task 2
[INFO  18:32:12] epoch 0: train_acc: 0.1085 	 test_acc: 0.1019
[INFO  18:32:27] epoch 1: train_acc: 0.1016 	 test_acc: 0.1043
[INFO  18:32:42] epoch 2: train_acc: 0.1041 	 test_acc: 0.0971
[INFO  18:32:57] epoch 3: train_acc: 0.0995 	 test_acc: 0.0993
[INFO  18:33:12] epoch 4: train_acc: 0.1024 	 test_acc: 0.1014
[INFO  18:33:27] epoch 5: train_acc: 0.0999 	 test_acc: 0.0993
[INFO  18:33:42] epoch 6: train_acc: 0.1007 	 test_acc: 0.1020
[INFO  18:33:57] epoch 7: train_acc: 0.0992 	 test_acc: 0.1036
[INFO  18:34:12] epoch 8: train_acc: 0.0986 	 test_acc: 0.1012
[INFO  18:34:27] epoch 9: train_acc: 0.0989 	 test_acc: 0.1031
[INFO  18:34:30] Task accuracies: {
    "task1": 0.1034,
    "task2": 0.1032
}
[INFO  18:34:30] Mean task accuracy: 0.1033
[INFO  18:34:30] Training run_id 25 with learning_rate 0.0001, beta_1 -100,beta_2 10 and freeze False
[INFO  18:34:30] Start experiment with parametrization:
{
    "dataset": {
        "name": "perm_mnist",
        "kwargs": {
            "batch_size": 100,
            "num_tasks": 10
        }
    },
    "cl_method": "generative_replay",
    "criterion": "cross_entropy",
    "beta_1": -100,
    "beta_2": 10,
    "enc_dimensions": [
        784,
        200,
        200,
        10
    ],
    "dec_class_dimensions": [
        10,
        10
    ],
    "dec_rec_dimensions": [
        10,
        200,
        200,
        784
    ],
    "n_bottleneck": 10,
    "epochs": 10,
    "freeze": false,
    "learning_rate": 0.0001,
    "nonlinearity": "relu",
    "mult_mlp": false,
    "n_replay": 1000,
    "optimizer": "adam",
    "replay_weight": 0.999,
    "seed": null,
    "test_samples": 1,
    "vae_batch_size": 128,
    "vae_epochs": 10,
    "vae_lr": 0.005,
    "vae_n_gaussian": 100,
    "vae_n_hidden": 400,
    "model": "comparison_model",
    "log_dir": "",
    "task": "perm_mnist_vib"
}
[INFO  18:34:30] Starting training of task 1
[INFO  18:34:43] epoch 0: train_acc: 0.1036 	 test_acc: 0.1034
[INFO  18:34:56] epoch 1: train_acc: 0.1037 	 test_acc: 0.1023
[INFO  18:35:10] epoch 2: train_acc: 0.1032 	 test_acc: 0.1039
[INFO  18:35:23] epoch 3: train_acc: 0.1051 	 test_acc: 0.1049
[INFO  18:35:36] epoch 4: train_acc: 0.1031 	 test_acc: 0.1045
[INFO  18:35:49] epoch 5: train_acc: 0.1039 	 test_acc: 0.1035
[INFO  18:36:02] epoch 6: train_acc: 0.1043 	 test_acc: 0.1043
[INFO  18:36:15] epoch 7: train_acc: 0.1032 	 test_acc: 0.1052
[INFO  18:36:29] epoch 8: train_acc: 0.1022 	 test_acc: 0.1071
[INFO  18:36:42] epoch 9: train_acc: 0.1052 	 test_acc: 0.1058
[INFO  18:39:01] Task accuracies: {
    "task1": 0.1052,
    "task2": 0.1015
}
[INFO  18:39:01] Mean task accuracy: 0.1052
[INFO  18:39:01] Update replay buffer for generative replay.
[INFO  18:39:03] Starting training of task 2
[INFO  18:39:18] epoch 0: train_acc: 0.1055 	 test_acc: 0.1062
[INFO  18:39:33] epoch 1: train_acc: 0.1066 	 test_acc: 0.1090
[INFO  18:39:48] epoch 2: train_acc: 0.1092 	 test_acc: 0.1060
[INFO  18:40:03] epoch 3: train_acc: 0.1086 	 test_acc: 0.1037
[INFO  18:40:18] epoch 4: train_acc: 0.1061 	 test_acc: 0.1080
[INFO  18:40:33] epoch 5: train_acc: 0.1066 	 test_acc: 0.1120
[INFO  18:40:48] epoch 6: train_acc: 0.1058 	 test_acc: 0.1039
[INFO  18:41:03] epoch 7: train_acc: 0.1058 	 test_acc: 0.1059
[INFO  18:41:18] epoch 8: train_acc: 0.1054 	 test_acc: 0.1049
[INFO  18:41:33] epoch 9: train_acc: 0.1051 	 test_acc: 0.1056
[INFO  18:41:36] Task accuracies: {
    "task1": 0.1055,
    "task2": 0.1057
}
[INFO  18:41:36] Mean task accuracy: 0.1056
[INFO  18:41:36] Training run_id 26 with learning_rate 0.0001, beta_1 -100,beta_2 10 and freeze False
[INFO  18:41:36] Start experiment with parametrization:
{
    "dataset": {
        "name": "perm_mnist",
        "kwargs": {
            "batch_size": 100,
            "num_tasks": 10
        }
    },
    "cl_method": "generative_replay",
    "criterion": "cross_entropy",
    "beta_1": -100,
    "beta_2": 10,
    "enc_dimensions": [
        784,
        200,
        200,
        100
    ],
    "dec_class_dimensions": [
        100,
        10
    ],
    "dec_rec_dimensions": [
        100,
        200,
        200,
        784
    ],
    "n_bottleneck": 100,
    "epochs": 10,
    "freeze": false,
    "learning_rate": 0.0001,
    "nonlinearity": "relu",
    "mult_mlp": false,
    "n_replay": 1000,
    "optimizer": "adam",
    "replay_weight": 0.999,
    "seed": null,
    "test_samples": 1,
    "vae_batch_size": 128,
    "vae_epochs": 10,
    "vae_lr": 0.005,
    "vae_n_gaussian": 100,
    "vae_n_hidden": 400,
    "model": "vib_model",
    "log_dir": "",
    "task": "perm_mnist_vib"
}
[INFO  18:41:36] Starting training of task 1
[INFO  18:41:50] epoch 0: train_acc: 0.1309 	 test_acc: 0.1725
[INFO  18:42:05] epoch 1: train_acc: 0.2843 	 test_acc: 0.4098
[INFO  18:42:19] epoch 2: train_acc: 0.5374 	 test_acc: 0.6480
[INFO  18:42:33] epoch 3: train_acc: 0.6826 	 test_acc: 0.7205
[INFO  18:42:47] epoch 4: train_acc: 0.7347 	 test_acc: 0.7693
[INFO  18:43:01] epoch 5: train_acc: 0.7677 	 test_acc: 0.7880
[INFO  18:43:16] epoch 6: train_acc: 0.7884 	 test_acc: 0.8082
[INFO  18:43:30] epoch 7: train_acc: 0.8083 	 test_acc: 0.8278
[INFO  18:43:44] epoch 8: train_acc: 0.8269 	 test_acc: 0.8422
[INFO  18:43:58] epoch 9: train_acc: 0.8365 	 test_acc: 0.8489
[INFO  18:44:01] Task accuracies: {
    "task1": 0.8489,
    "task2": 0.1094
}
[INFO  18:44:01] Mean task accuracy: 0.8489
[INFO  18:44:01] Update replay buffer for generative replay.
[INFO  18:44:03] Starting training of task 2
[INFO  18:44:18] epoch 0: train_acc: 0.1053 	 test_acc: 0.1065
[INFO  18:44:33] epoch 1: train_acc: 0.1060 	 test_acc: 0.1064
[INFO  18:44:47] epoch 2: train_acc: 0.1022 	 test_acc: 0.1009
[INFO  18:45:02] epoch 3: train_acc: 0.1024 	 test_acc: 0.1033
[INFO  18:45:17] epoch 4: train_acc: 0.1003 	 test_acc: 0.1009
[INFO  18:45:32] epoch 5: train_acc: 0.0956 	 test_acc: 0.0951
[INFO  18:45:47] epoch 6: train_acc: 0.0938 	 test_acc: 0.0918
[INFO  18:46:02] epoch 7: train_acc: 0.0926 	 test_acc: 0.0883
[INFO  18:46:16] epoch 8: train_acc: 0.0902 	 test_acc: 0.0895
[INFO  18:46:31] epoch 9: train_acc: 0.0904 	 test_acc: 0.0890
[INFO  18:46:34] Task accuracies: {
    "task1": 0.0894,
    "task2": 0.0891
}
[INFO  18:46:34] Mean task accuracy: 0.0892
[INFO  18:46:34] Training run_id 27 with learning_rate 0.0001, beta_1 -100,beta_2 10 and freeze False
[INFO  18:46:35] Start experiment with parametrization:
{
    "dataset": {
        "name": "perm_mnist",
        "kwargs": {
            "batch_size": 100,
            "num_tasks": 10
        }
    },
    "cl_method": "generative_replay",
    "criterion": "cross_entropy",
    "beta_1": -100,
    "beta_2": 10,
    "enc_dimensions": [
        784,
        200,
        200,
        100
    ],
    "dec_class_dimensions": [
        100,
        10
    ],
    "dec_rec_dimensions": [
        100,
        200,
        200,
        784
    ],
    "n_bottleneck": 100,
    "epochs": 10,
    "freeze": false,
    "learning_rate": 0.0001,
    "nonlinearity": "relu",
    "mult_mlp": false,
    "n_replay": 1000,
    "optimizer": "adam",
    "replay_weight": 0.999,
    "seed": null,
    "test_samples": 1,
    "vae_batch_size": 128,
    "vae_epochs": 10,
    "vae_lr": 0.005,
    "vae_n_gaussian": 100,
    "vae_n_hidden": 400,
    "model": "comparison_model",
    "log_dir": "",
    "task": "perm_mnist_vib"
}
[INFO  18:46:35] Starting training of task 1
[INFO  18:46:48] epoch 0: train_acc: 0.1032 	 test_acc: 0.1031
[INFO  18:47:01] epoch 1: train_acc: 0.1010 	 test_acc: 0.1018
[INFO  18:47:14] epoch 2: train_acc: 0.1025 	 test_acc: 0.1051
[INFO  18:47:27] epoch 3: train_acc: 0.1045 	 test_acc: 0.1008
[INFO  18:47:40] epoch 4: train_acc: 0.1042 	 test_acc: 0.0988
[INFO  18:47:53] epoch 5: train_acc: 0.1047 	 test_acc: 0.1020
[INFO  18:48:06] epoch 6: train_acc: 0.1045 	 test_acc: 0.1089
[INFO  18:48:19] epoch 7: train_acc: 0.1051 	 test_acc: 0.1087
[INFO  18:48:32] epoch 8: train_acc: 0.1061 	 test_acc: 0.1049
[INFO  18:48:45] epoch 9: train_acc: 0.1067 	 test_acc: 0.1050
[INFO  18:51:04] Task accuracies: {
    "task1": 0.1049,
    "task2": 0.109
}
[INFO  18:51:04] Mean task accuracy: 0.1049
[INFO  18:51:04] Update replay buffer for generative replay.
[INFO  18:51:06] Starting training of task 2
[INFO  18:51:21] epoch 0: train_acc: 0.1067 	 test_acc: 0.1027
[INFO  18:51:36] epoch 1: train_acc: 0.1076 	 test_acc: 0.1064
[INFO  18:51:51] epoch 2: train_acc: 0.1103 	 test_acc: 0.1136
[INFO  18:52:06] epoch 3: train_acc: 0.1118 	 test_acc: 0.1125
[INFO  18:52:21] epoch 4: train_acc: 0.1123 	 test_acc: 0.1135
[INFO  18:52:36] epoch 5: train_acc: 0.1124 	 test_acc: 0.1135
[INFO  18:52:51] epoch 6: train_acc: 0.1124 	 test_acc: 0.1135
[INFO  18:53:07] epoch 7: train_acc: 0.1124 	 test_acc: 0.1135
[INFO  18:53:22] epoch 8: train_acc: 0.1124 	 test_acc: 0.1135
[INFO  18:53:37] epoch 9: train_acc: 0.1124 	 test_acc: 0.1135
[INFO  18:53:40] Task accuracies: {
    "task1": 0.1135,
    "task2": 0.1135
}
[INFO  18:53:40] Mean task accuracy: 0.1135
[INFO  18:53:40] Training run_id 28 with learning_rate 0.0001, beta_1 -100,beta_2 10 and freeze False
[INFO  18:53:40] Start experiment with parametrization:
{
    "dataset": {
        "name": "perm_mnist",
        "kwargs": {
            "batch_size": 100,
            "num_tasks": 10
        }
    },
    "cl_method": "generative_replay",
    "criterion": "cross_entropy",
    "beta_1": -100,
    "beta_2": 10,
    "enc_dimensions": [
        784,
        200,
        200,
        1000
    ],
    "dec_class_dimensions": [
        1000,
        10
    ],
    "dec_rec_dimensions": [
        1000,
        200,
        200,
        784
    ],
    "n_bottleneck": 1000,
    "epochs": 10,
    "freeze": false,
    "learning_rate": 0.0001,
    "nonlinearity": "relu",
    "mult_mlp": false,
    "n_replay": 1000,
    "optimizer": "adam",
    "replay_weight": 0.999,
    "seed": null,
    "test_samples": 1,
    "vae_batch_size": 128,
    "vae_epochs": 10,
    "vae_lr": 0.005,
    "vae_n_gaussian": 100,
    "vae_n_hidden": 400,
    "model": "vib_model",
    "log_dir": "",
    "task": "perm_mnist_vib"
}
[INFO  18:53:40] Starting training of task 1
[INFO  18:53:55] epoch 0: train_acc: 0.1504 	 test_acc: 0.2309
[INFO  18:54:09] epoch 1: train_acc: 0.4281 	 test_acc: 0.5831
[INFO  18:54:24] epoch 2: train_acc: 0.6635 	 test_acc: 0.7193
[INFO  18:54:38] epoch 3: train_acc: 0.7352 	 test_acc: 0.7613
[INFO  18:54:53] epoch 4: train_acc: 0.7636 	 test_acc: 0.7877
[INFO  18:55:07] epoch 5: train_acc: 0.7954 	 test_acc: 0.8142
[INFO  18:55:22] epoch 6: train_acc: 0.8146 	 test_acc: 0.8273
[INFO  18:55:36] epoch 7: train_acc: 0.8246 	 test_acc: 0.8361
[INFO  18:55:51] epoch 8: train_acc: 0.8306 	 test_acc: 0.8409
[INFO  18:56:06] epoch 9: train_acc: 0.8333 	 test_acc: 0.8411
[INFO  18:56:09] Task accuracies: {
    "task1": 0.8442,
    "task2": 0.0959
}
[INFO  18:56:09] Mean task accuracy: 0.8442
[INFO  18:56:09] Update replay buffer for generative replay.
[INFO  18:56:12] Starting training of task 2
[INFO  18:56:27] epoch 0: train_acc: 0.1062 	 test_acc: 0.1150
[INFO  18:56:42] epoch 1: train_acc: 0.1055 	 test_acc: 0.1034
[INFO  18:56:57] epoch 2: train_acc: 0.1021 	 test_acc: 0.0971
[INFO  18:57:12] epoch 3: train_acc: 0.1004 	 test_acc: 0.1060
[INFO  18:57:27] epoch 4: train_acc: 0.0969 	 test_acc: 0.0981
[INFO  18:57:42] epoch 5: train_acc: 0.0941 	 test_acc: 0.0953
[INFO  18:57:57] epoch 6: train_acc: 0.0929 	 test_acc: 0.0962
[INFO  18:58:12] epoch 7: train_acc: 0.0937 	 test_acc: 0.0923
[INFO  18:58:27] epoch 8: train_acc: 0.0929 	 test_acc: 0.0906
[INFO  18:58:42] epoch 9: train_acc: 0.0929 	 test_acc: 0.0905
[INFO  18:58:45] Task accuracies: {
    "task1": 0.0958,
    "task2": 0.096
}
[INFO  18:58:45] Mean task accuracy: 0.0959
[INFO  18:58:45] Training run_id 29 with learning_rate 0.0001, beta_1 -100,beta_2 10 and freeze False
[INFO  18:58:45] Start experiment with parametrization:
{
    "dataset": {
        "name": "perm_mnist",
        "kwargs": {
            "batch_size": 100,
            "num_tasks": 10
        }
    },
    "cl_method": "generative_replay",
    "criterion": "cross_entropy",
    "beta_1": -100,
    "beta_2": 10,
    "enc_dimensions": [
        784,
        200,
        200,
        1000
    ],
    "dec_class_dimensions": [
        1000,
        10
    ],
    "dec_rec_dimensions": [
        1000,
        200,
        200,
        784
    ],
    "n_bottleneck": 1000,
    "epochs": 10,
    "freeze": false,
    "learning_rate": 0.0001,
    "nonlinearity": "relu",
    "mult_mlp": false,
    "n_replay": 1000,
    "optimizer": "adam",
    "replay_weight": 0.999,
    "seed": null,
    "test_samples": 1,
    "vae_batch_size": 128,
    "vae_epochs": 10,
    "vae_lr": 0.005,
    "vae_n_gaussian": 100,
    "vae_n_hidden": 400,
    "model": "comparison_model",
    "log_dir": "",
    "task": "perm_mnist_vib"
}
[INFO  18:58:45] Starting training of task 1
[INFO  18:58:58] epoch 0: train_acc: 0.0987 	 test_acc: 0.1098
[INFO  18:59:11] epoch 1: train_acc: 0.1007 	 test_acc: 0.0971
[INFO  18:59:25] epoch 2: train_acc: 0.1013 	 test_acc: 0.0985
[INFO  18:59:38] epoch 3: train_acc: 0.1006 	 test_acc: 0.1003
[INFO  18:59:51] epoch 4: train_acc: 0.0989 	 test_acc: 0.1009
[INFO  19:00:04] epoch 5: train_acc: 0.1011 	 test_acc: 0.1003
[INFO  19:00:17] epoch 6: train_acc: 0.1006 	 test_acc: 0.1030
[INFO  19:00:30] epoch 7: train_acc: 0.1003 	 test_acc: 0.1076
[INFO  19:00:44] epoch 8: train_acc: 0.1030 	 test_acc: 0.1053
[INFO  19:00:57] epoch 9: train_acc: 0.1042 	 test_acc: 0.1070
[INFO  19:03:15] Task accuracies: {
    "task1": 0.1025,
    "task2": 0.1017
}
[INFO  19:03:15] Mean task accuracy: 0.1025
[INFO  19:03:15] Update replay buffer for generative replay.
[INFO  19:03:17] Starting training of task 2
[INFO  19:03:32] epoch 0: train_acc: 0.1027 	 test_acc: 0.1076
[INFO  19:03:47] epoch 1: train_acc: 0.1043 	 test_acc: 0.1040
[INFO  19:04:01] epoch 2: train_acc: 0.1085 	 test_acc: 0.1087
[INFO  19:04:16] epoch 3: train_acc: 0.1075 	 test_acc: 0.1115
[INFO  19:04:31] epoch 4: train_acc: 0.1120 	 test_acc: 0.1132
[INFO  19:04:46] epoch 5: train_acc: 0.1124 	 test_acc: 0.1136
[INFO  19:05:01] epoch 6: train_acc: 0.1124 	 test_acc: 0.1135
[INFO  19:05:15] epoch 7: train_acc: 0.1123 	 test_acc: 0.1138
[INFO  19:05:30] epoch 8: train_acc: 0.1124 	 test_acc: 0.1136
[INFO  19:05:45] epoch 9: train_acc: 0.1123 	 test_acc: 0.1132
[INFO  19:05:48] Task accuracies: {
    "task1": 0.1133,
    "task2": 0.1132
}
[INFO  19:05:48] Mean task accuracy: 0.1133
[INFO  19:05:48] Training run_id 30 with learning_rate 0.0001, beta_1 -100,beta_2 100 and freeze False
[INFO  19:05:48] Start experiment with parametrization:
{
    "dataset": {
        "name": "perm_mnist",
        "kwargs": {
            "batch_size": 100,
            "num_tasks": 10
        }
    },
    "cl_method": "generative_replay",
    "criterion": "cross_entropy",
    "beta_1": -100,
    "beta_2": 100,
    "enc_dimensions": [
        784,
        200,
        200,
        10
    ],
    "dec_class_dimensions": [
        10,
        10
    ],
    "dec_rec_dimensions": [
        10,
        200,
        200,
        784
    ],
    "n_bottleneck": 10,
    "epochs": 10,
    "freeze": false,
    "learning_rate": 0.0001,
    "nonlinearity": "relu",
    "mult_mlp": false,
    "n_replay": 1000,
    "optimizer": "adam",
    "replay_weight": 0.999,
    "seed": null,
    "test_samples": 1,
    "vae_batch_size": 128,
    "vae_epochs": 10,
    "vae_lr": 0.005,
    "vae_n_gaussian": 100,
    "vae_n_hidden": 400,
    "model": "vib_model",
    "log_dir": "",
    "task": "perm_mnist_vib"
}
[INFO  19:05:48] Starting training of task 1
[INFO  19:06:03] epoch 0: train_acc: 0.0993 	 test_acc: 0.1184
[INFO  19:06:17] epoch 1: train_acc: 0.1590 	 test_acc: 0.2071
[INFO  19:06:31] epoch 2: train_acc: 0.2464 	 test_acc: 0.3305
[INFO  19:06:45] epoch 3: train_acc: 0.4078 	 test_acc: 0.4676
[INFO  19:07:00] epoch 4: train_acc: 0.4906 	 test_acc: 0.5206
[INFO  19:07:14] epoch 5: train_acc: 0.5412 	 test_acc: 0.5624
[INFO  19:07:29] epoch 6: train_acc: 0.5937 	 test_acc: 0.6401
[INFO  19:07:43] epoch 7: train_acc: 0.6584 	 test_acc: 0.6890
[INFO  19:07:58] epoch 8: train_acc: 0.6986 	 test_acc: 0.7237
[INFO  19:08:12] epoch 9: train_acc: 0.7241 	 test_acc: 0.7424
[INFO  19:08:15] Task accuracies: {
    "task1": 0.7416,
    "task2": 0.157
}
[INFO  19:08:15] Mean task accuracy: 0.7416
[INFO  19:08:15] Update replay buffer for generative replay.
[INFO  19:08:17] Starting training of task 2
[INFO  19:08:32] epoch 0: train_acc: 0.1045 	 test_acc: 0.1023
[INFO  19:08:47] epoch 1: train_acc: 0.0985 	 test_acc: 0.0963
[INFO  19:09:02] epoch 2: train_acc: 0.0998 	 test_acc: 0.1019
[INFO  19:09:17] epoch 3: train_acc: 0.1021 	 test_acc: 0.1012
[INFO  19:09:32] epoch 4: train_acc: 0.0990 	 test_acc: 0.0986
[INFO  19:09:47] epoch 5: train_acc: 0.1021 	 test_acc: 0.1042
[INFO  19:10:02] epoch 6: train_acc: 0.1020 	 test_acc: 0.1070
[INFO  19:10:17] epoch 7: train_acc: 0.1024 	 test_acc: 0.1028
[INFO  19:10:32] epoch 8: train_acc: 0.1026 	 test_acc: 0.1016
[INFO  19:10:47] epoch 9: train_acc: 0.1011 	 test_acc: 0.1031
[INFO  19:10:50] Task accuracies: {
    "task1": 0.1048,
    "task2": 0.1051
}
[INFO  19:10:50] Mean task accuracy: 0.1049
[INFO  19:10:50] Training run_id 31 with learning_rate 0.0001, beta_1 -100,beta_2 100 and freeze False
[INFO  19:10:50] Start experiment with parametrization:
{
    "dataset": {
        "name": "perm_mnist",
        "kwargs": {
            "batch_size": 100,
            "num_tasks": 10
        }
    },
    "cl_method": "generative_replay",
    "criterion": "cross_entropy",
    "beta_1": -100,
    "beta_2": 100,
    "enc_dimensions": [
        784,
        200,
        200,
        10
    ],
    "dec_class_dimensions": [
        10,
        10
    ],
    "dec_rec_dimensions": [
        10,
        200,
        200,
        784
    ],
    "n_bottleneck": 10,
    "epochs": 10,
    "freeze": false,
    "learning_rate": 0.0001,
    "nonlinearity": "relu",
    "mult_mlp": false,
    "n_replay": 1000,
    "optimizer": "adam",
    "replay_weight": 0.999,
    "seed": null,
    "test_samples": 1,
    "vae_batch_size": 128,
    "vae_epochs": 10,
    "vae_lr": 0.005,
    "vae_n_gaussian": 100,
    "vae_n_hidden": 400,
    "model": "comparison_model",
    "log_dir": "",
    "task": "perm_mnist_vib"
}
[INFO  19:10:50] Starting training of task 1
[INFO  19:11:03] epoch 0: train_acc: 0.1013 	 test_acc: 0.1003
[INFO  19:11:16] epoch 1: train_acc: 0.1010 	 test_acc: 0.1009
[INFO  19:11:30] epoch 2: train_acc: 0.0985 	 test_acc: 0.1040
[INFO  19:11:43] epoch 3: train_acc: 0.1002 	 test_acc: 0.1004
[INFO  19:11:56] epoch 4: train_acc: 0.0994 	 test_acc: 0.1003
[INFO  19:12:09] epoch 5: train_acc: 0.1035 	 test_acc: 0.1063
[INFO  19:12:22] epoch 6: train_acc: 0.1013 	 test_acc: 0.1009
[INFO  19:12:35] epoch 7: train_acc: 0.1016 	 test_acc: 0.1026
[INFO  19:12:49] epoch 8: train_acc: 0.1001 	 test_acc: 0.1037
[INFO  19:13:02] epoch 9: train_acc: 0.1043 	 test_acc: 0.1095
[INFO  19:15:21] Task accuracies: {
    "task1": 0.1053,
    "task2": 0.1059
}
[INFO  19:15:21] Mean task accuracy: 0.1053
[INFO  19:15:21] Update replay buffer for generative replay.
[INFO  19:15:23] Starting training of task 2
[INFO  19:15:38] epoch 0: train_acc: 0.1059 	 test_acc: 0.1046
[INFO  19:15:53] epoch 1: train_acc: 0.1071 	 test_acc: 0.1091
[INFO  19:16:08] epoch 2: train_acc: 0.1093 	 test_acc: 0.1106
[INFO  19:16:23] epoch 3: train_acc: 0.1109 	 test_acc: 0.1131
[INFO  19:16:38] epoch 4: train_acc: 0.1122 	 test_acc: 0.1135
[INFO  19:16:53] epoch 5: train_acc: 0.1124 	 test_acc: 0.1135
[INFO  19:17:08] epoch 6: train_acc: 0.1124 	 test_acc: 0.1135
[INFO  19:17:23] epoch 7: train_acc: 0.1124 	 test_acc: 0.1135
[INFO  19:17:38] epoch 8: train_acc: 0.1124 	 test_acc: 0.1135
[INFO  19:17:53] epoch 9: train_acc: 0.1124 	 test_acc: 0.1135
[INFO  19:17:56] Task accuracies: {
    "task1": 0.1135,
    "task2": 0.1135
}
[INFO  19:17:56] Mean task accuracy: 0.1135
[INFO  19:17:56] Training run_id 32 with learning_rate 0.0001, beta_1 -100,beta_2 100 and freeze False
[INFO  19:17:57] Start experiment with parametrization:
{
    "dataset": {
        "name": "perm_mnist",
        "kwargs": {
            "batch_size": 100,
            "num_tasks": 10
        }
    },
    "cl_method": "generative_replay",
    "criterion": "cross_entropy",
    "beta_1": -100,
    "beta_2": 100,
    "enc_dimensions": [
        784,
        200,
        200,
        100
    ],
    "dec_class_dimensions": [
        100,
        10
    ],
    "dec_rec_dimensions": [
        100,
        200,
        200,
        784
    ],
    "n_bottleneck": 100,
    "epochs": 10,
    "freeze": false,
    "learning_rate": 0.0001,
    "nonlinearity": "relu",
    "mult_mlp": false,
    "n_replay": 1000,
    "optimizer": "adam",
    "replay_weight": 0.999,
    "seed": null,
    "test_samples": 1,
    "vae_batch_size": 128,
    "vae_epochs": 10,
    "vae_lr": 0.005,
    "vae_n_gaussian": 100,
    "vae_n_hidden": 400,
    "model": "vib_model",
    "log_dir": "",
    "task": "perm_mnist_vib"
}
[INFO  19:17:57] Starting training of task 1
[INFO  19:18:11] epoch 0: train_acc: 0.1192 	 test_acc: 0.1529
[INFO  19:18:26] epoch 1: train_acc: 0.2101 	 test_acc: 0.2551
[INFO  19:18:40] epoch 2: train_acc: 0.2970 	 test_acc: 0.3400
[INFO  19:18:55] epoch 3: train_acc: 0.3837 	 test_acc: 0.4385
[INFO  19:19:09] epoch 4: train_acc: 0.4799 	 test_acc: 0.5491
[INFO  19:19:24] epoch 5: train_acc: 0.5766 	 test_acc: 0.6153
[INFO  19:19:38] epoch 6: train_acc: 0.6233 	 test_acc: 0.6507
[INFO  19:19:53] epoch 7: train_acc: 0.6499 	 test_acc: 0.6636
[INFO  19:20:07] epoch 8: train_acc: 0.6676 	 test_acc: 0.6829
[INFO  19:20:22] epoch 9: train_acc: 0.6758 	 test_acc: 0.6873
[INFO  19:20:25] Task accuracies: {
    "task1": 0.6761,
    "task2": 0.1156
}
[INFO  19:20:25] Mean task accuracy: 0.6761
[INFO  19:20:25] Update replay buffer for generative replay.
[INFO  19:20:27] Starting training of task 2
[INFO  19:20:42] epoch 0: train_acc: 0.1035 	 test_acc: 0.1035
[INFO  19:20:57] epoch 1: train_acc: 0.1003 	 test_acc: 0.0995
[INFO  19:21:12] epoch 2: train_acc: 0.0998 	 test_acc: 0.0953
[INFO  19:21:27] epoch 3: train_acc: 0.1009 	 test_acc: 0.1008
[INFO  19:21:42] epoch 4: train_acc: 0.1006 	 test_acc: 0.1060
[INFO  19:21:57] epoch 5: train_acc: 0.0999 	 test_acc: 0.1017
[INFO  19:22:12] epoch 6: train_acc: 0.1009 	 test_acc: 0.1040
[INFO  19:22:27] epoch 7: train_acc: 0.1016 	 test_acc: 0.1020
[INFO  19:22:42] epoch 8: train_acc: 0.0988 	 test_acc: 0.0964
[INFO  19:22:57] epoch 9: train_acc: 0.0990 	 test_acc: 0.1009
[INFO  19:23:00] Task accuracies: {
    "task1": 0.1027,
    "task2": 0.1007
}
[INFO  19:23:00] Mean task accuracy: 0.1017
[INFO  19:23:00] Training run_id 33 with learning_rate 0.0001, beta_1 -100,beta_2 100 and freeze False
[INFO  19:23:00] Start experiment with parametrization:
{
    "dataset": {
        "name": "perm_mnist",
        "kwargs": {
            "batch_size": 100,
            "num_tasks": 10
        }
    },
    "cl_method": "generative_replay",
    "criterion": "cross_entropy",
    "beta_1": -100,
    "beta_2": 100,
    "enc_dimensions": [
        784,
        200,
        200,
        100
    ],
    "dec_class_dimensions": [
        100,
        10
    ],
    "dec_rec_dimensions": [
        100,
        200,
        200,
        784
    ],
    "n_bottleneck": 100,
    "epochs": 10,
    "freeze": false,
    "learning_rate": 0.0001,
    "nonlinearity": "relu",
    "mult_mlp": false,
    "n_replay": 1000,
    "optimizer": "adam",
    "replay_weight": 0.999,
    "seed": null,
    "test_samples": 1,
    "vae_batch_size": 128,
    "vae_epochs": 10,
    "vae_lr": 0.005,
    "vae_n_gaussian": 100,
    "vae_n_hidden": 400,
    "model": "comparison_model",
    "log_dir": "",
    "task": "perm_mnist_vib"
}
[INFO  19:23:00] Starting training of task 1
[INFO  19:23:13] epoch 0: train_acc: 0.0994 	 test_acc: 0.0988
[INFO  19:23:26] epoch 1: train_acc: 0.1014 	 test_acc: 0.1011
[INFO  19:23:39] epoch 2: train_acc: 0.1004 	 test_acc: 0.0988
[INFO  19:23:52] epoch 3: train_acc: 0.1016 	 test_acc: 0.1077
[INFO  19:24:05] epoch 4: train_acc: 0.1008 	 test_acc: 0.1005
[INFO  19:24:18] epoch 5: train_acc: 0.1015 	 test_acc: 0.1072
[INFO  19:24:31] epoch 6: train_acc: 0.1023 	 test_acc: 0.1098
[INFO  19:24:44] epoch 7: train_acc: 0.1031 	 test_acc: 0.1042
[INFO  19:24:57] epoch 8: train_acc: 0.1037 	 test_acc: 0.1023
[INFO  19:25:10] epoch 9: train_acc: 0.1030 	 test_acc: 0.1037
[INFO  19:27:26] Task accuracies: {
    "task1": 0.1003,
    "task2": 0.1021
}
[INFO  19:27:26] Mean task accuracy: 0.1003
[INFO  19:27:26] Update replay buffer for generative replay.
[INFO  19:27:28] Starting training of task 2
[INFO  19:27:43] epoch 0: train_acc: 0.1056 	 test_acc: 0.1069
[INFO  19:27:58] epoch 1: train_acc: 0.1079 	 test_acc: 0.1104
[INFO  19:28:13] epoch 2: train_acc: 0.1098 	 test_acc: 0.1121
[INFO  19:28:28] epoch 3: train_acc: 0.1115 	 test_acc: 0.1140
[INFO  19:28:43] epoch 4: train_acc: 0.1122 	 test_acc: 0.1135
[INFO  19:28:58] epoch 5: train_acc: 0.1124 	 test_acc: 0.1135
[INFO  19:29:13] epoch 6: train_acc: 0.1124 	 test_acc: 0.1135
[INFO  19:29:28] epoch 7: train_acc: 0.1124 	 test_acc: 0.1135
[INFO  19:29:43] epoch 8: train_acc: 0.1124 	 test_acc: 0.1135
[INFO  19:29:58] epoch 9: train_acc: 0.1124 	 test_acc: 0.1135
[INFO  19:30:01] Task accuracies: {
    "task1": 0.1135,
    "task2": 0.1135
}
[INFO  19:30:01] Mean task accuracy: 0.1135
[INFO  19:30:01] Training run_id 34 with learning_rate 0.0001, beta_1 -100,beta_2 100 and freeze False
[INFO  19:30:02] Start experiment with parametrization:
{
    "dataset": {
        "name": "perm_mnist",
        "kwargs": {
            "batch_size": 100,
            "num_tasks": 10
        }
    },
    "cl_method": "generative_replay",
    "criterion": "cross_entropy",
    "beta_1": -100,
    "beta_2": 100,
    "enc_dimensions": [
        784,
        200,
        200,
        1000
    ],
    "dec_class_dimensions": [
        1000,
        10
    ],
    "dec_rec_dimensions": [
        1000,
        200,
        200,
        784
    ],
    "n_bottleneck": 1000,
    "epochs": 10,
    "freeze": false,
    "learning_rate": 0.0001,
    "nonlinearity": "relu",
    "mult_mlp": false,
    "n_replay": 1000,
    "optimizer": "adam",
    "replay_weight": 0.999,
    "seed": null,
    "test_samples": 1,
    "vae_batch_size": 128,
    "vae_epochs": 10,
    "vae_lr": 0.005,
    "vae_n_gaussian": 100,
    "vae_n_hidden": 400,
    "model": "vib_model",
    "log_dir": "",
    "task": "perm_mnist_vib"
}
[INFO  19:30:02] Starting training of task 1
[INFO  19:30:16] epoch 0: train_acc: 0.1226 	 test_acc: 0.1555
[INFO  19:30:31] epoch 1: train_acc: 0.2054 	 test_acc: 0.2480
[INFO  19:30:45] epoch 2: train_acc: 0.2727 	 test_acc: 0.3135
[INFO  19:31:00] epoch 3: train_acc: 0.3429 	 test_acc: 0.3826
[INFO  19:31:14] epoch 4: train_acc: 0.4138 	 test_acc: 0.4674
[INFO  19:31:29] epoch 5: train_acc: 0.4996 	 test_acc: 0.5489
[INFO  19:31:44] epoch 6: train_acc: 0.5788 	 test_acc: 0.6018
[INFO  19:31:58] epoch 7: train_acc: 0.6200 	 test_acc: 0.6484
[INFO  19:32:13] epoch 8: train_acc: 0.6453 	 test_acc: 0.6578
[INFO  19:32:27] epoch 9: train_acc: 0.6603 	 test_acc: 0.6789
[INFO  19:32:30] Task accuracies: {
    "task1": 0.6785,
    "task2": 0.123
}
[INFO  19:32:30] Mean task accuracy: 0.6785
[INFO  19:32:30] Update replay buffer for generative replay.
[INFO  19:32:32] Starting training of task 2
[INFO  19:32:47] epoch 0: train_acc: 0.1015 	 test_acc: 0.0953
[INFO  19:33:02] epoch 1: train_acc: 0.0979 	 test_acc: 0.1022
[INFO  19:33:17] epoch 2: train_acc: 0.0998 	 test_acc: 0.0986
[INFO  19:33:32] epoch 3: train_acc: 0.0988 	 test_acc: 0.0981
[INFO  19:33:47] epoch 4: train_acc: 0.0974 	 test_acc: 0.0939
[INFO  19:34:02] epoch 5: train_acc: 0.0998 	 test_acc: 0.0951
[INFO  19:34:17] epoch 6: train_acc: 0.0979 	 test_acc: 0.0990
[INFO  19:34:32] epoch 7: train_acc: 0.0977 	 test_acc: 0.0955
[INFO  19:34:47] epoch 8: train_acc: 0.0971 	 test_acc: 0.0939
[INFO  19:35:02] epoch 9: train_acc: 0.0983 	 test_acc: 0.0956
[INFO  19:35:05] Task accuracies: {
    "task1": 0.0969,
    "task2": 0.0963
}
[INFO  19:35:05] Mean task accuracy: 0.0966
[INFO  19:35:05] Training run_id 35 with learning_rate 0.0001, beta_1 -100,beta_2 100 and freeze False
[INFO  19:35:06] Start experiment with parametrization:
{
    "dataset": {
        "name": "perm_mnist",
        "kwargs": {
            "batch_size": 100,
            "num_tasks": 10
        }
    },
    "cl_method": "generative_replay",
    "criterion": "cross_entropy",
    "beta_1": -100,
    "beta_2": 100,
    "enc_dimensions": [
        784,
        200,
        200,
        1000
    ],
    "dec_class_dimensions": [
        1000,
        10
    ],
    "dec_rec_dimensions": [
        1000,
        200,
        200,
        784
    ],
    "n_bottleneck": 1000,
    "epochs": 10,
    "freeze": false,
    "learning_rate": 0.0001,
    "nonlinearity": "relu",
    "mult_mlp": false,
    "n_replay": 1000,
    "optimizer": "adam",
    "replay_weight": 0.999,
    "seed": null,
    "test_samples": 1,
    "vae_batch_size": 128,
    "vae_epochs": 10,
    "vae_lr": 0.005,
    "vae_n_gaussian": 100,
    "vae_n_hidden": 400,
    "model": "comparison_model",
    "log_dir": "",
    "task": "perm_mnist_vib"
}
[INFO  19:35:06] Starting training of task 1
[INFO  19:35:19] epoch 0: train_acc: 0.1001 	 test_acc: 0.1016
[INFO  19:35:32] epoch 1: train_acc: 0.0996 	 test_acc: 0.1066
[INFO  19:35:45] epoch 2: train_acc: 0.1008 	 test_acc: 0.1000
[INFO  19:35:59] epoch 3: train_acc: 0.1015 	 test_acc: 0.0972
[INFO  19:36:12] epoch 4: train_acc: 0.1005 	 test_acc: 0.1043
[INFO  19:36:25] epoch 5: train_acc: 0.1034 	 test_acc: 0.1025
[INFO  19:36:38] epoch 6: train_acc: 0.1027 	 test_acc: 0.1039
[INFO  19:36:51] epoch 7: train_acc: 0.1011 	 test_acc: 0.0955
[INFO  19:37:05] epoch 8: train_acc: 0.1030 	 test_acc: 0.1032
[INFO  19:37:18] epoch 9: train_acc: 0.1017 	 test_acc: 0.1029
[INFO  19:39:38] Task accuracies: {
    "task1": 0.0992,
    "task2": 0.104
}
[INFO  19:39:38] Mean task accuracy: 0.0992
[INFO  19:39:38] Update replay buffer for generative replay.
[INFO  19:39:41] Starting training of task 2
[INFO  19:39:56] epoch 0: train_acc: 0.1014 	 test_acc: 0.1056
[INFO  19:40:11] epoch 1: train_acc: 0.1052 	 test_acc: 0.1011
[INFO  19:40:26] epoch 2: train_acc: 0.1068 	 test_acc: 0.1089
[INFO  19:40:41] epoch 3: train_acc: 0.1085 	 test_acc: 0.1132
[INFO  19:40:56] epoch 4: train_acc: 0.1118 	 test_acc: 0.1132
[INFO  19:41:11] epoch 5: train_acc: 0.1124 	 test_acc: 0.1134
[INFO  19:41:26] epoch 6: train_acc: 0.1123 	 test_acc: 0.1140
[INFO  19:41:41] epoch 7: train_acc: 0.1126 	 test_acc: 0.1119
[INFO  19:41:56] epoch 8: train_acc: 0.1123 	 test_acc: 0.1139
[INFO  19:42:11] epoch 9: train_acc: 0.1125 	 test_acc: 0.1127
[INFO  19:42:14] Task accuracies: {
    "task1": 0.1134,
    "task2": 0.112
}
[INFO  19:42:14] Mean task accuracy: 0.1127
Training VAE on task: 1
Training VAE on task: 1
Training VAE on task: 1
Training VAE on task: 1
Training VAE on task: 1
Training VAE on task: 1
Training VAE on task: 1
Training VAE on task: 1
Training VAE on task: 1
Training VAE on task: 1
Training VAE on task: 1
Training VAE on task: 1
Training VAE on task: 1
Training VAE on task: 1
Training VAE on task: 1
Training VAE on task: 1
Training VAE on task: 1
Training VAE on task: 1
done
